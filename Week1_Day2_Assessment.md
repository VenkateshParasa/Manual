# Day 2: Testing Levels & Types - Assessment Questions

## Assessment Overview

This document contains all assessment questions for Day 2. These questions are also available in the interactive web application with two modes:

- **Quick Mode**: 10 questions, 15 minutes
- **Full Mode**: 35 questions, 45 minutes

---

## Assessment Questions

### Section A: Multiple Choice Questions (15 questions)

**1. Which testing level is typically performed by developers?**
   a) System Testing
   b) Unit Testing
   c) Acceptance Testing
   d) Integration Testing

**2. What is the primary purpose of smoke testing?**
   a) Detailed feature testing
   b) Build verification - check if critical features work
   c) Performance testing
   d) Security testing

**3. In which integration approach are all modules integrated simultaneously?**
   a) Top-Down
   b) Bottom-Up
   c) Big Bang
   d) Sandwich

**4. What is the main focus of System Testing?**
   a) Individual components
   b) Module interfaces
   c) Complete integrated system
   d) User acceptance

**5. Which testing type verifies that new changes haven't broken existing functionality?**
   a) Smoke Testing
   b) Sanity Testing
   c) Regression Testing
   d) Re-testing

**6. What does UAT stand for?**
   a) Unit Acceptance Testing
   b) User Acceptance Testing
   c) Universal Application Testing
   d) Unified Automated Testing

**7. Which integration approach uses stubs?**
   a) Bottom-Up
   b) Top-Down
   c) Big Bang
   d) None of the above

**8. What is the difference between smoke and sanity testing?**
   a) Smoke is wide & shallow, Sanity is narrow & deep
   b) Smoke is narrow & deep, Sanity is wide & shallow
   c) They are the same
   d) Smoke is automated, Sanity is manual

**9. Which testing level is performed by end users?**
   a) Unit Testing
   b) Integration Testing
   c) System Testing
   d) Acceptance Testing

**10. What is re-testing?**
   a) Testing the entire application again
   b) Testing to verify a specific bug fix
   c) Testing after code changes
   d) Testing with new test cases

**11. Which non-functional testing type measures system performance under load?**
   a) Security Testing
   b) Usability Testing
   c) Performance Testing
   d) Compatibility Testing

**12. What is the purpose of Alpha Testing?**
   a) Testing by end users
   b) Internal testing before external release
   c) Testing in production
   d) Automated testing

**13. Which integration approach uses drivers?**
   a) Top-Down
   b) Bottom-Up
   c) Big Bang
   d) Sandwich

**14. What is the main goal of Beta Testing?**
   a) Internal validation
   b) Real-world testing by external users
   c) Performance testing
   d) Security testing

**15. Which testing type focuses on user-friendliness?**
   a) Performance Testing
   b) Security Testing
   c) Usability Testing
   d) Compatibility Testing

---

### Section B: True/False Questions (10 questions)

**1. Unit testing is primarily performed by QA testers.**
   ☐ True  ☐ False

**2. Regression testing should be performed after every code change.**
   ☐ True  ☐ False

**3. Smoke testing is deeper and more thorough than sanity testing.**
   ☐ True  ☐ False

**4. Integration testing focuses on testing individual components in isolation.**
   ☐ True  ☐ False

**5. System testing includes both functional and non-functional testing.**
   ☐ True  ☐ False

**6. Alpha testing is performed by external users in their environment.**
   ☐ True  ☐ False

**7. Re-testing and regression testing are the same thing.**
   ☐ True  ☐ False

**8. Top-Down integration requires the use of stubs.**
   ☐ True  ☐ False

**9. Acceptance testing is performed before system testing.**
   ☐ True  ☐ False

**10. Performance testing is a type of non-functional testing.**
   ☐ True  ☐ False

---

### Section C: Scenario-Based Questions (10 questions)

**1. You are testing a new build. After deploying it to the test environment, what should be your first testing activity and why?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**2. Your project uses Bottom-Up integration. The database layer is ready but the UI is not. How would you test the database layer?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**3. A critical bug was fixed in the payment module. What types of testing would you perform and in what order?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**4. You have 500 regression test cases but only 2 days to test before release. How would you approach this?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**5. During UAT, business users report that the system is too slow. What type of testing should have been performed earlier to catch this?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**6. You're testing a mobile banking app. List the different testing levels you would perform and what each level would focus on.**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**7. A new feature was added to the login module. The smoke test passed, but should you proceed with full testing? What additional checks would you perform?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**8. Your team is planning to use Hybrid/Sandwich integration for a large ERP system. Explain how you would organize the testing.**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**9. During system testing, you find that the application works on Chrome but not on Firefox. What type of testing is this, and what should be your next steps?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

**10. You're conducting Alpha testing with 50 internal employees. What metrics would you track and what would constitute a successful Alpha test?**

   **Your Answer:**
   _____________________________________
   _____________________________________
   _____________________________________

---

## Answer Key

### Section A: MCQ Answers

1. **b) Unit Testing**
   - Unit testing is performed by developers to test individual components

2. **b) Build verification - check if critical features work**
   - Smoke testing is a quick check to verify the build is stable enough for detailed testing

3. **c) Big Bang**
   - Big Bang integration integrates all modules at once

4. **c) Complete integrated system**
   - System testing tests the entire system as a whole

5. **c) Regression Testing**
   - Regression testing ensures new changes haven't broken existing functionality

6. **b) User Acceptance Testing**
   - UAT is performed by end users to validate the system meets their needs

7. **b) Top-Down**
   - Top-Down integration uses stubs to simulate lower-level modules

8. **a) Smoke is wide & shallow, Sanity is narrow & deep**
   - Smoke testing covers many features briefly; Sanity testing focuses deeply on specific areas

9. **d) Acceptance Testing**
   - Acceptance testing (UAT) is performed by end users

10. **b) Testing to verify a specific bug fix**
    - Re-testing confirms that a reported defect has been fixed

11. **c) Performance Testing**
    - Performance testing measures system behavior under various load conditions

12. **b) Internal testing before external release**
    - Alpha testing is internal testing performed before Beta testing

13. **b) Bottom-Up**
    - Bottom-Up integration uses drivers to simulate higher-level modules

14. **b) Real-world testing by external users**
    - Beta testing involves real users testing in real environments

15. **c) Usability Testing**
    - Usability testing evaluates user-friendliness and user experience

---

### Section B: True/False Answers

1. **False** - Unit testing is primarily performed by developers, not QA testers

2. **True** - Regression testing should be performed after code changes to ensure no new bugs are introduced

3. **False** - Smoke testing is wide and shallow; Sanity testing is narrow and deep

4. **False** - Integration testing focuses on interfaces between components, not individual components

5. **True** - System testing includes both functional (features) and non-functional (performance, security) testing

6. **False** - Alpha testing is internal testing; Beta testing is performed by external users

7. **False** - Re-testing verifies specific bug fixes; Regression testing ensures no new bugs in existing features

8. **True** - Top-Down integration uses stubs to simulate lower-level modules not yet developed

9. **False** - Acceptance testing is performed after system testing

10. **True** - Performance testing is a non-functional testing type

---

### Section C: Scenario Answers (Sample Answers)

**1. First Testing Activity After Build Deployment:**

**Answer:**
Perform **Smoke Testing** first because:
- Verifies the build is stable enough for detailed testing
- Checks if critical functionalities work (login, navigation, key features)
- Takes only 30-60 minutes
- If smoke test fails, build is rejected immediately, saving testing time
- Prevents wasting time on detailed testing of an unstable build

**Steps:**
1. Deploy build to test environment
2. Run smoke test suite (20-30 critical test cases)
3. If passed: Proceed with detailed testing
4. If failed: Reject build, return to development

---

**2. Testing Database Layer with Bottom-Up Integration:**

**Answer:**
Use **Drivers** to test the database layer:

**Approach:**
1. Create test drivers (test harnesses) that simulate the UI and business logic layers
2. Drivers will call database functions directly
3. Test database operations: CRUD operations, transactions, data validation
4. Verify data integrity, constraints, and stored procedures

**Example:**
```
Driver Test Cases:
- Insert user record → Verify in database
- Update user record → Verify changes
- Delete user record → Verify deletion
- Test transaction rollback
- Test concurrent access
```

**Benefits:**
- Test database layer independently
- Don't wait for UI completion
- Identify database issues early

---

**3. Testing After Payment Module Bug Fix:**

**Answer:**
Perform testing in this order:

**1. Re-testing (Confirmation Testing):**
- Test the exact scenario that caused the bug
- Verify the specific bug is fixed
- Use same test data and steps

**2. Sanity Testing:**
- Deep testing of payment module
- Test related payment scenarios
- Verify no side effects from the fix

**3. Regression Testing:**
- Test other modules that interact with payment (cart, checkout, order)
- Ensure the fix didn't break existing functionality
- Run automated regression suite if available

**4. Smoke Testing:**
- Quick end-to-end test of critical flows
- Verify overall system stability

---

**4. Handling 500 Regression Tests in 2 Days:**

**Answer:**
Use **Risk-Based Testing** approach:

**Strategy:**
1. **Prioritize Test Cases:**
   - P0 (Critical): 100 test cases - Must run (business critical features)
   - P1 (High): 200 test cases - Should run (important features)
   - P2 (Medium): 150 test cases - Run if time permits
   - P3 (Low): 50 test cases - Skip or defer

2. **Focus on High-Risk Areas:**
   - Recently changed modules
   - Payment and checkout flows
   - User authentication
   - Data integrity operations

3. **Leverage Automation:**
   - Run automated tests overnight
   - Manual testing for new/unstable features

4. **Parallel Execution:**
   - Multiple testers working simultaneously
   - Divide test cases by module

**Result:** Execute 300 critical test cases, achieving 80% coverage of high-risk areas

---

**5. Performance Issues Found in UAT:**

**Answer:**
**Performance Testing** should have been performed earlier during **System Testing** phase.

**What Should Have Been Done:**
1. **Load Testing:** Test with expected user load (e.g., 1000 concurrent users)
2. **Stress Testing:** Test beyond normal capacity to find breaking point
3. **Endurance Testing:** Test for extended periods (24 hours) to identify memory leaks
4. **Spike Testing:** Test sudden load increases

**Why It Was Missed:**
- Performance testing not included in test plan
- No performance requirements defined
- Tested only with single user
- No performance benchmarks set

**Lesson:** Non-functional testing (performance, security, usability) must be part of system testing, not discovered in UAT

---

**6. Testing Levels for Mobile Banking App:**

**Answer:**

**1. Unit Testing (Developers):**
- Individual functions (login validation, balance calculation)
- Code coverage: 85%+
- Test frameworks: JUnit, XCTest

**2. Integration Testing (Developers + QA):**
- API integration with backend
- Database connectivity
- Third-party service integration (payment gateway)
- Biometric authentication integration

**3. System Testing (QA Team):**
- **Functional:** All features (login, transfer, bill pay, statements)
- **Performance:** Response time, concurrent users
- **Security:** Encryption, authentication, authorization
- **Usability:** User interface, navigation
- **Compatibility:** iOS/Android versions, devices

**4. Acceptance Testing (Business Users + Customers):**
- **Alpha Testing:** 50 bank employees test for 1 week
- **Beta Testing:** 500 real customers test for 2 weeks
- **UAT:** Business validates against requirements

---

**7. After Smoke Test Passes:**

**Answer:**
Yes, proceed with full testing, but perform **Sanity Testing** first on the login module:

**Additional Checks:**
1. **Sanity Test Login Module:**
   - Test all login scenarios deeply
   - Valid/invalid credentials
   - Password reset flow
   - Session management
   - Account lockout after failed attempts
   - Remember me functionality

2. **Check Related Modules:**
   - User registration (if login changed, registration might be affected)
   - User profile
   - Authentication across the application

3. **Review Code Changes:**
   - Understand what was changed
   - Identify potential impact areas

4. **Run Regression Tests:**
   - Focus on authentication-related test cases
   - Test user flows that depend on login

**Decision:** If sanity test passes, proceed with full regression testing

---

**8. Hybrid/Sandwich Integration for ERP System:**

**Answer:**

**Team Organization:**

**Top-Down Team (Team A - 3 testers):**
- Start from UI layer (Dashboard, Reports, Forms)
- Use stubs for business logic
- Week 1-2: Test UI independently
- Week 3: Integrate with real business logic

**Bottom-Up Team (Team B - 3 testers):**
- Start from database layer
- Use drivers to test data access
- Week 1-2: Test database and data layer
- Week 3: Integrate with business logic

**Integration Point (Week 3):**
- Both teams meet at business logic layer
- Remove stubs and drivers
- Test complete integration
- Resolve interface issues

**Modules:**
```
Level 1 (UI): Dashboard, Reports, Forms
Level 2 (Business Logic): Order Management, Inventory, HR, Finance
Level 3 (Data): Database APIs, Data Validation, Data Access Layer
```

**Benefits:**
- Parallel testing reduces timeline by 40%
- Both UI and database tested thoroughly
- Integration issues identified at middle layer

---

**9. Browser Compatibility Issue:**

**Answer:**
This is **Compatibility Testing** (specifically Browser Compatibility Testing).

**Next Steps:**

1. **Document the Issue:**
   - Browser: Firefox (version)
   - OS: Windows/Mac
   - Specific feature not working
   - Error messages/console logs
   - Screenshots

2. **Reproduce on Multiple Firefox Versions:**
   - Latest version
   - Previous 2 versions
   - Identify if version-specific

3. **Test on Other Browsers:**
   - Chrome (working)
   - Safari
   - Edge
   - Identify if Firefox-only issue

4. **Analyze Root Cause:**
   - Browser-specific CSS issues
   - JavaScript compatibility
   - Browser API differences

5. **Expand Compatibility Testing:**
   - Create compatibility matrix
   - Test on all supported browsers
   - Test on different OS combinations

6. **Report to Development:**
   - Detailed bug report
   - Steps to reproduce
   - Browser console errors

---

**10. Alpha Testing Metrics and Success Criteria:**

**Answer:**

**Metrics to Track:**

**1. Participation Metrics:**
- Active participants: Target 90% (45/50)
- Daily active users
- Average session time
- Feature usage statistics

**2. Bug Metrics:**
- Total bugs reported
- Bugs by severity (Critical, High, Medium, Low)
- Bugs by module
- Bug resolution time

**3. Performance Metrics:**
- App crashes
- Response time issues
- Memory usage
- Battery drain

**4. User Feedback:**
- User satisfaction survey (1-5 rating)
- Feature requests
- Usability issues
- Pain points

**Success Criteria:**

✅ **Participation:** 85%+ active participation
✅ **Stability:** <5 critical bugs, <15 high-priority bugs
✅ **Performance:** <10 crash reports, acceptable response times
✅ **User Satisfaction:** Average rating >4/5
✅ **Coverage:** All major features tested
✅ **Feedback:** Actionable feedback collected

**Decision to Proceed to Beta:**
- All critical bugs fixed
- High-priority bugs <5
- User satisfaction >4/5
- No major blockers identified

---

## Notes

- These questions are available in the interactive web application
- The app provides immediate feedback and explanations
- Use Quick Mode (10 questions) for practice
- Use Full Mode (35 questions) for comprehensive assessment
- Passing score: 70%
- Review feature available to learn from mistakes

---

*For the interactive assessment experience, visit the web application and navigate to Day 2 Assessment.*