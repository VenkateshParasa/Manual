# Day 20: Industry Best Practices & Standards
## Comprehensive Study Guide

---

## Table of Contents
1. [Quality Standards Overview](#quality-standards-overview)
2. [ISO/IEC Standards for Software Testing](#iso-iec-standards)
3. [ISTQB Guidelines & Certification](#istqb-guidelines)
4. [Test Process Improvement Models](#test-process-improvement-models)
5. [Agile & DevOps Best Practices](#agile-devops-best-practices)
6. [Industry-Specific Testing](#industry-specific-testing)
7. [Practical Exercises](#practical-exercises)
8. [Assessment Questions](#assessment-questions)

---

## Quality Standards Overview

### 1.1 Why Standards Matter

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
IMPORTANCE OF QUALITY STANDARDS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Definition:
Quality standards are documented agreements containing technical
specifications or criteria to ensure materials, products, processes,
and services are fit for their purpose.

WHY STANDARDS MATTER IN SOFTWARE TESTING:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. CONSISTENCY:
   âœ“ Common language across teams
   âœ“ Repeatable processes
   âœ“ Predictable outcomes
   âœ“ Reduced variation

2. QUALITY ASSURANCE:
   âœ“ Proven practices
   âœ“ Risk mitigation
   âœ“ Customer satisfaction
   âœ“ Defect prevention

3. COMPLIANCE:
   âœ“ Regulatory requirements (FDA, HIPAA, SOC 2)
   âœ“ Industry mandates
   âœ“ Legal protection
   âœ“ Audit readiness

4. EFFICIENCY:
   âœ“ No need to "reinvent the wheel"
   âœ“ Faster onboarding
   âœ“ Better collaboration
   âœ“ Shared best practices

5. CREDIBILITY:
   âœ“ Professional recognition
   âœ“ Market differentiation
   âœ“ Customer trust
   âœ“ Competitive advantage

BENEFITS VS CHALLENGES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Benefits:
âœ“ Improved quality
âœ“ Reduced costs (long-term)
âœ“ Risk mitigation
âœ“ Process improvement
âœ“ Team alignment
âœ“ Knowledge sharing
âœ“ Audit compliance

Challenges:
âš  Initial implementation cost
âš  Learning curve
âš  May seem bureaucratic
âš  Requires ongoing maintenance
âš  Can slow initial development
âš  Need organizational buy-in

Example Impact:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Without Standards:
Company A: Each team uses different bug tracking, test processes,
           documentation formats. New hires take 3 months to be
           productive. Cross-team collaboration is difficult.
           
With Standards (ISO 29119):
Company B: All teams follow same test processes, documentation.
           New hires productive in 3 weeks. Easy knowledge transfer.
           Passed audit on first attempt.

MAJOR TESTING STANDARDS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

International:
1. ISO/IEC 29119 - Software Testing
2. ISO/IEC 25010 - Software Quality Models
3. ISO 9001 - Quality Management Systems
4. IEEE 829 - Software Test Documentation

Industry Bodies:
1. ISTQB - International Software Testing Qualifications Board
2. IEEE - Institute of Electrical and Electronics Engineers
3. ISO - International Organization for Standardization
4. ANSI - American National Standards Institute

Methodologies:
1. TMMi - Test Maturity Model Integration
2. TPI NEXT - Test Process Improvement
3. CTP - Critical Testing Processes
4. STEP - Systematic Test and Evaluation Process

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

### 1.2 Standards Landscape

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SOFTWARE TESTING STANDARDS ECOSYSTEM
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

STANDARDS HIERARCHY:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Level 1: International Standards (ISO/IEC)
          â”‚
          â”œâ”€â†’ Globally recognized
          â”œâ”€â†’ High-level principles
          â”œâ”€â†’ Industry-agnostic
          â””â”€â†’ Examples: ISO 29119, ISO 25010

Level 2: Industry Standards (ISTQB, IEEE)
          â”‚
          â”œâ”€â†’ Specific to software testing
          â”œâ”€â†’ Detailed practices
          â”œâ”€â†’ Certification bodies
          â””â”€â†’ Examples: ISTQB Syllabus, IEEE 829

Level 3: Company/Organization Standards
          â”‚
          â”œâ”€â†’ Internal policies
          â”œâ”€â†’ Customized for context
          â”œâ”€â†’ Based on Level 1 & 2
          â””â”€â†’ Examples: Company QA Manual

Level 4: Project/Team Guidelines
          â”‚
          â”œâ”€â†’ Project-specific
          â”œâ”€â†’ Team agreements
          â”œâ”€â†’ Tool-specific
          â””â”€â†’ Examples: Project Test Plan Template

STANDARD TYPES BY PURPOSE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. PROCESS STANDARDS:
   What: Define HOW to perform testing activities
   Examples:
   - ISO 29119: Software testing processes
   - TMMi: Test process maturity levels
   - Agile Testing Quadrants
   
   Cover:
   âœ“ Test planning
   âœ“ Test design
   âœ“ Test execution
   âœ“ Test closure

2. PRODUCT STANDARDS:
   What: Define characteristics of test artifacts
   Examples:
   - IEEE 829: Test documentation
   - ISO 25010: Software quality characteristics
   
   Cover:
   âœ“ Test plan format
   âœ“ Test case structure
   âœ“ Bug report format
   âœ“ Test report content

3. COMPETENCY STANDARDS:
   What: Define required skills and knowledge
   Examples:
   - ISTQB: Tester competencies
   - IEEE CSDP: Software development professional
   
   Cover:
   âœ“ Tester skill levels
   âœ“ Certification criteria
   âœ“ Training requirements
   âœ“ Professional ethics

COMPLIANCE LEVELS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Level 1: Aware
- Team knows standards exist
- No formal implementation
- Ad-hoc usage
Status: âŒ Not compliant

Level 2: Partially Compliant
- Some practices adopted
- Not organization-wide
- Inconsistent application
Status: ğŸŸ¡ Improving

Level 3: Compliant
- Formal adoption
- Consistent application
- Documentation in place
- Regular audits
Status: âœ… Compliant

Level 4: Certified
- External audit passed
- Official certification
- Ongoing compliance monitoring
- Continuous improvement
Status: âœ…âœ… Certified

Example Progression:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Year 1:
- Awareness training on ISO 29119
- Pilot team implements standard
- Document gaps
Action: Assess current state

Year 2:
- Roll out to all teams
- Update test processes
- Tool alignment
- Training program
Action: Implement organization-wide

Year 3:
- Prepare for external audit
- Process refinement
- Documentation complete
- Pre-audit assessment
Action: Certification preparation

Year 4:
- External audit
- ISO 29119 certification achieved
- Continuous improvement process
- Annual surveillance audits
Action: Maintain and improve

WHEN TO ADOPT STANDARDS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

MUST Adopt:
âœ“ Regulated industries (healthcare, finance, aerospace)
âœ“ Government contracts
âœ“ Safety-critical systems
âœ“ Large enterprises with multiple teams
âœ“ Organizations seeking certification

SHOULD Consider:
âœ“ Growing teams (>10 people)
âœ“ High-quality requirements
âœ“ Customer demand
âœ“ Process improvement initiatives
âœ“ Knowledge retention needs

MAY Skip (Initially):
âœ“ Small startups (<5 people)
âœ“ Prototypes/POCs
âœ“ Non-critical applications
âœ“ Very tight budgets
Note: Can adopt later as organization matures

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ISO/IEC Standards for Software Testing

### 2.1 ISO/IEC 29119 - Software Testing Standard

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ISO/IEC 29119: SOFTWARE TESTING STANDARD
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Overview:
International standard for software testing processes, covering all
aspects from organizational test policy to individual test execution.

Published: 2013 (Parts 1-4), 2016 (Part 5)
Maintained by: ISO/IEC Joint Technical Committee

STRUCTURE (5 Parts):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PART 1: CONCEPTS AND DEFINITIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Common vocabulary for testing

Key Concepts:
âœ“ Test Process
âœ“ Test Levels (Unit, Integration, System, Acceptance)
âœ“ Test Types (Functional, Non-functional)
âœ“ Testing Roles
âœ“ Test Artifacts

Benefits:
- Eliminates confusion from ambiguous terms
- Enables clear communication
- Basis for other parts

Example Terms Defined:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Term             â”‚ ISO 29119 Definition                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Test Case        â”‚ Set of preconditions, inputs,       â”‚
â”‚                  â”‚ actions, expected results, and      â”‚
â”‚                  â”‚ postconditions                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Test Condition   â”‚ Testable aspect of a component or   â”‚
â”‚                  â”‚ system identified as a basis for    â”‚
â”‚                  â”‚ testing                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Defect           â”‚ Imperfection or deficiency where    â”‚
â”‚                  â”‚ component does not meet requirementsâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Test Execution   â”‚ Process of running a test on the    â”‚
â”‚                  â”‚ test item                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PART 2: TEST PROCESSES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Define testing processes at different levels

THREE PROCESS LEVELS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ORGANIZATIONAL TEST PROCESS
   Scope: Entire organization
   
   Activities:
   âœ“ Define test policy
   âœ“ Establish test strategy
   âœ“ Test process assessment
   âœ“ Continuous improvement
   
   Artifacts:
   - Organizational Test Policy
   - Organizational Test Strategy
   - Test Process Improvement Plan
   
   Example Policy Statement:
   "All software released by ACME Corp shall be tested according to
    ISO 29119 standards. Minimum pass criteria: 95% test coverage,
    zero critical defects, 90% pass rate."

2. TEST MANAGEMENT PROCESS
   Scope: Test project
   
   Activities:
   âœ“ Test planning
   âœ“ Test monitoring & control
   âœ“ Test completion
   
   Sub-processes:
   a) Test Planning:
      - Define test scope
      - Identify test conditions
      - Design test approach
      - Determine resources
      - Schedule tests
      
   b) Test Monitoring & Control:
      - Track progress vs plan
      - Measure test execution
      - Identify deviations
      - Take corrective action
      
   c) Test Completion:
      - Evaluate exit criteria
      - Document lessons learned
      - Archive test artifacts
      - Release test environment
   
   Artifacts:
   - Test Plan
   - Test Progress Reports
   - Test Completion Report

3. DYNAMIC TEST PROCESS
   Scope: Individual test execution
   
   Activities:
   âœ“ Test design
   âœ“ Test environment setup
   âœ“ Test execution
   âœ“ Test incident reporting
   
   Sub-processes:
   a) Test Design:
      - Identify test conditions
      - Derive test cases
      - Identify test data
      
   b) Test Environment Setup:
      - Configure test environment
      - Prepare test data
      - Verify environment readiness
      
   c) Test Execution:
      - Run test procedures
      - Log results
      - Compare actual vs expected
      
   d) Test Incident Reporting:
      - Document anomalies
      - Classify incidents
      - Track to resolution
   
   Artifacts:
   - Test Design Specification
   - Test Cases
   - Test Procedures
   - Test Execution Logs
   - Test Incident Reports

PROCESS FLOW EXAMPLE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Organizational Level:
[Test Policy] â†’ [Test Strategy] â†’ [Process Assessment]
       â”‚
       â†“
Test Management Level:
[Test Planning] â†’ [Test Monitoring] â†’ [Test Completion]
       â”‚                    â†‘
       â†“                    â”‚
Dynamic Test Level:
[Test Design] â†’ [Environment Setup] â†’ [Test Execution] â†’
                                        [Incident Reporting]

PART 3: TEST DOCUMENTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Templates for test documentation

KEY DOCUMENTS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Organizational Test Policy (Template)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Structure:
1. Policy Scope
2. Testing Principles
3. Test Process Requirements
4. Roles & Responsibilities
5. Compliance & Review

Example:
```
ORGANIZATIONAL TEST POLICY

1. SCOPE:
   This policy applies to all software development at XYZ Corp.

2. PRINCIPLES:
   - Testing is integral to development
   - Quality is everyone's responsibility
   - Risk-based test approach
   - Continuous improvement

3. REQUIREMENTS:
   - All projects must have test plans
   - Minimum 80% code coverage
   - Zero critical defects before release
   - All defects tracked in Jira

4. ROLES:
   - QA Manager: Overall test strategy
   - Test Leads: Project test plans
   - Testers: Test execution
   - Developers: Unit testing

5. COMPLIANCE:
   Annual audit of test processes
```

2. Test Plan (Template)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Mandatory Sections (ISO 29119-3):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1.  Test Plan Identifier
2.  Introduction
3.  Test Items
4.  Features to be Tested
5.  Features Not to be Tested
6.  Test Approach
7.  Pass/Fail Criteria
8.  Suspension & Resumption Criteria
9.  Test Deliverables
10. Test Environment
11. Responsibilities
12. Staffing & Training Needs
13. Schedule
14. Risks & Contingencies
15. Approvals

Example Test Plan Excerpt:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TEST PLAN
Project: E-commerce Checkout Redesign
Version: 1.2
Date: January 10, 2026
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. TEST PLAN IDENTIFIER: TP-ECOM-CHECKOUT-v1.2

2. INTRODUCTION:
   This plan describes testing for checkout redesign (Release 3.5).
   Scope: Payment integration, order confirmation, receipt generation.

3. TEST ITEMS:
   - Checkout UI (Web + Mobile)
   - Payment Gateway Integration (Stripe)
   - Order Processing Service
   - Email Notification Service

4. FEATURES TO BE TESTED:
   âœ“ Payment processing (Credit Card, PayPal, Apple Pay)
   âœ“ Order confirmation workflow
   âœ“ Receipt generation (PDF)
   âœ“ Error handling and validation
   âœ“ Mobile responsiveness

5. FEATURES NOT TO BE TESTED:
   âœ— User authentication (unchanged from previous release)
   âœ— Shopping cart (separate test plan)
   âœ— Product catalog

6. TEST APPROACH:
   Test Levels:
   - Unit Testing (Developers)
   - Integration Testing (QA)
   - System Testing (QA)
   - UAT (Business Users)
   
   Test Types:
   - Functional Testing
   - Security Testing (PCI compliance)
   - Performance Testing (1000 concurrent users)
   - Usability Testing
   - Accessibility Testing (WCAG 2.1 Level AA)

7. PASS/FAIL CRITERIA:
   Pass Criteria:
   âœ“ 100% of P0 test cases passed
   âœ“ 95% of P1 test cases passed
   âœ“ Zero critical defects open
   âœ“ Code coverage â‰¥ 85%
   âœ“ Performance: <3 sec checkout time
   
   Fail Criteria:
   âœ— Any P0 test case fails
   âœ— Critical defects open
   âœ— Performance >5 sec checkout time

8. SUSPENSION CRITERIA:
   Testing will be suspended if:
   - Test environment unavailable >4 hours
   - >20% of test cases blocked
   - Critical build issue
   
   Resumption Criteria:
   - Environment restored
   - Blockers resolved
   - Stable build deployed

9. TEST DELIVERABLES:
   - Test Plan (this document)
   - Test Cases (500 cases in TestRail)
   - Test Execution Reports (daily)
   - Defect Reports (Jira)
   - Test Completion Report
   - Test Metrics Dashboard

10. TEST ENVIRONMENT:
    - QA Environment: qa.ecommerce.com
    - Browsers: Chrome, Safari, Firefox, Edge (latest 2 versions)
    - Mobile: iOS 15+, Android 11+
    - Payment: Stripe Test Mode
    - Database: MySQL 8.0 (test data)

11. RESPONSIBILITIES:
    Test Manager: Sarah Chen
    Test Leads: John Smith (Web), Maria Garcia (Mobile)
    Testers: 5 QA engineers
    Developers: Support for defect fixes

12. STAFFING & TRAINING:
    - 5 QA engineers (full-time, 4 weeks)
    - Training: Stripe API (2 hours)
    - Skills Required: Web testing, API testing, SQL

13. SCHEDULE:
    Test Planning: Jan 10-12 (3 days)
    Test Design: Jan 13-17 (5 days)
    Test Execution: Jan 18-31 (10 days)
    Regression: Feb 1-3 (3 days)
    UAT: Feb 4-7 (4 days)
    Release: Feb 10

14. RISKS & CONTINGENCIES:
    Risk 1: Payment gateway test environment unstable
    Likelihood: Medium | Impact: High
    Mitigation: Use mock server as backup
    
    Risk 2: Limited mobile test devices
    Likelihood: High | Impact: Medium
    Mitigation: Use BrowserStack cloud devices
    
    Risk 3: Late requirement changes
    Likelihood: Medium | Impact: High
    Mitigation: Change control process, buffer in schedule

15. APPROVALS:
    QA Manager: _________________ Date: _______
    Project Manager: ____________ Date: _______
    Product Owner: ______________ Date: _______

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

3. Test Case Specification (Template)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ISO 29119-3 Test Case Format:
```
Test Case ID: TC-CHECKOUT-001
Test Case Name: Verify successful checkout with credit card
Priority: P0 (Critical)
Test Level: System Test
Test Type: Functional

Preconditions:
- User logged in
- Items in shopping cart (total: $100)
- Test credit card available

Test Data:
Card Number: 4242 4242 4242 4242
Expiry: 12/25
CVV: 123
ZIP: 12345

Test Steps:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step â”‚ Action                    â”‚ Expected Result            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1   â”‚ Click "Checkout" button   â”‚ Redirected to checkout pageâ”‚
â”‚  2   â”‚ Enter shipping address    â”‚ Address validated, saved   â”‚
â”‚  3   â”‚ Select "Credit Card"      â”‚ Payment form displayed     â”‚
â”‚  4   â”‚ Enter card details        â”‚ Form accepts input         â”‚
â”‚  5   â”‚ Click "Place Order"       â”‚ Processing indicator shown â”‚
â”‚  6   â”‚ Wait for confirmation     â”‚ Order confirmation page    â”‚
â”‚      â”‚                           â”‚ Order# displayed           â”‚
â”‚      â”‚                           â”‚ Receipt emailed            â”‚
â”‚      â”‚                           â”‚ Cart emptied               â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Postconditions:
- Order created in database
- Payment processed
- Email sent
- Inventory updated

Pass/Fail Criteria:
PASS: All expected results achieved
FAIL: Any expected result not achieved

Actual Result: [To be filled during execution]
Status: [Pass/Fail/Blocked]
Tested By: [Name]
Test Date: [Date]
Comments: [Notes]
```

4. Test Incident Report (Defect Report Template)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ISO 29119-3 Incident Report Format:
```
Incident ID: INC-2026-001
Summary: Payment fails for orders >$1000
Priority: Critical (P0)
Severity: High

Test Case: TC-CHECKOUT-005
Test Environment: QA
Date Detected: 2026-01-10
Detected By: Sarah Chen

Description:
Payment processing fails when order total exceeds $1000.
Error message: "Payment gateway timeout"

Steps to Reproduce:
1. Add items totaling $1200 to cart
2. Proceed to checkout
3. Enter payment details (card: 4242...)
4. Click "Place Order"
5. Observe error

Expected Result:
Payment should process successfully
Order confirmation displayed

Actual Result:
Error message: "Payment gateway timeout"
Payment not processed
Order not created

Environment:
Browser: Chrome 120
OS: macOS Sontura
Server: qa.ecommerce.com
Build: v3.5.0-RC1
Database: MySQL 8.0 (QA)

Impact:
- Affects all orders >$1000
- Blocks checkout for high-value transactions
- Revenue impact: High
- User impact: Critical

Frequency: 100% (reproducible 5/5 times)

Workaround:
Split order into multiple transactions <$1000 each

Attachments:
- Screenshot: payment_error.png
- Browser Console Log: console_log.txt
- Network HAR file: network.har

Assigned To: John Developer
Target Fix Date: 2026-01-12
Priority Justification: Blocks core business functionality

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

PART 4: TEST TECHNIQUES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Standardized test design techniques

CATEGORIES OF TEST TECHNIQUES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Specification-Based (Black-Box):
   âœ“ Equivalence Partitioning
   âœ“ Boundary Value Analysis
   âœ“ Decision Tables
   âœ“ State Transition Testing
   âœ“ Use Case Testing
   âœ“ Classification Trees

2. Structure-Based (White-Box):
   âœ“ Statement Coverage
   âœ“ Decision Coverage
   âœ“ Condition Coverage
   âœ“ Path Coverage

3. Experience-Based:
   âœ“ Error Guessing
   âœ“ Exploratory Testing
   âœ“ Checklist-Based Testing

Example: Equivalence Partitioning (ISO 29119-4)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Requirement: Age field accepts values 18-65

Partitions:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partition  â”‚ Range       â”‚ Valid/Invalidâ”‚ Test Value     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Below min  â”‚ < 18        â”‚ Invalid      â”‚ 17             â”‚
â”‚ Valid rangeâ”‚ 18-65       â”‚ Valid        â”‚ 30, 50         â”‚
â”‚ Above max  â”‚ > 65        â”‚ Invalid      â”‚ 66             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Test Cases:
TC-001: Input 17 â†’ Expect: Error "Must be 18 or older"
TC-002: Input 30 â†’ Expect: Accepted
TC-003: Input 50 â†’ Expect: Accepted
TC-004: Input 66 â†’ Expect: Error "Maximum age is 65"

PART 5: KEYWORD-DRIVEN TESTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Standardize keyword-driven test approach

Concept: Test cases written using keywords (actions)

Example:
```
Test Case: Login with valid credentials

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword  â”‚ Object     â”‚ Data         â”‚ Expected Resultâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Navigate â”‚ URL        â”‚ /login       â”‚ Page loads     â”‚
â”‚ Input    â”‚ Username   â”‚ testuser     â”‚ Text entered   â”‚
â”‚ Input    â”‚ Password   â”‚ Test@123     â”‚ Text entered   â”‚
â”‚ Click    â”‚ LoginBtn   â”‚              â”‚ Login success  â”‚
â”‚ Verify   â”‚ Dashboard  â”‚              â”‚ Displayed      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Benefits:
âœ“ Non-programmers can write tests
âœ“ Reusable keywords
âœ“ Easier maintenance
âœ“ Test data separation

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
IMPLEMENTING ISO 29119
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

STEP-BY-STEP IMPLEMENTATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 1: Assessment (Month 1-2)
--------------------------------
âœ“ Review current test processes
âœ“ Identify gaps vs ISO 29119
âœ“ Stakeholder buy-in
âœ“ Form implementation team

Phase 2: Planning (Month 3-4)
------------------------------
âœ“ Define organizational test policy
âœ“ Customize templates
âœ“ Tool selection/configuration
âœ“ Training plan

Phase 3: Pilot (Month 5-6)
---------------------------
âœ“ Select pilot project
âœ“ Apply ISO 29119 processes
âœ“ Use document templates
âœ“ Collect feedback
âœ“ Refine approach

Phase 4: Rollout (Month 7-12)
------------------------------
âœ“ Train all teams
âœ“ Apply to all projects
âœ“ Establish governance
âœ“ Regular process audits

Phase 5: Certification (Year 2)
--------------------------------
âœ“ Pre-assessment audit
âœ“ Address non-conformances
âœ“ External certification audit
âœ“ Achieve certification

COSTS & BENEFITS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Costs:
- Training: $10,000-50,000
- Tools/Templates: $5,000-20,000
- Consulting: $20,000-100,000 (optional)
- Time Investment: 6-12 months
- Certification Audit: $15,000-50,000

Benefits:
âœ“ Improved quality
âœ“ Reduced defects (15-30%)
âœ“ Better process efficiency
âœ“ Market differentiation
âœ“ Customer confidence
âœ“ Audit readiness
âœ“ Knowledge retention

ROI: Typically positive after 12-18 months

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

### 2.2 ISO/IEC 25010 - Software Quality Model

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ISO/IEC 25010: SOFTWARE QUALITY MODEL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose:
Defines quality characteristics for evaluating software products

Published: 2011 (Replaced ISO 9126)
Part of: SQuaRE (Systems and Software Quality Requirements
         and Evaluation) series

TWO QUALITY MODELS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. PRODUCT QUALITY MODEL (Internal & External)
2. QUALITY IN USE MODEL

PRODUCT QUALITY MODEL (8 Characteristics):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. FUNCTIONAL SUITABILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Degree to which product provides functions that meet stated needs

   Sub-characteristics:
   a) Functional Completeness
      - All specified functions implemented
      
   b) Functional Correctness
      - Functions provide correct results
      
   c) Functional Appropriateness
      - Functions facilitate specified tasks

   Test Approach:
   âœ“ Requirements-based testing
   âœ“ Functional test coverage
   âœ“ Acceptance testing
   
   Example Tests:
   - All user stories tested
   - All acceptance criteria verified
   - Edge cases covered

2. PERFORMANCE EFFICIENCY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Performance relative to resources used

   Sub-characteristics:
   a) Time Behavior
      - Response times, throughput
      
   b) Resource Utilization
      - CPU, memory, network usage
      
   c) Capacity
      - Maximum limits

   Test Approach:
   âœ“ Performance testing
   âœ“ Load testing
   âœ“ Stress testing
   âœ“ Scalability testing
   
   Example Tests:
   - Page load time <2 seconds
   - Support 1000 concurrent users
   - Memory usage <500MB

3. COMPATIBILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Ability to exchange information and co-exist with other systems

   Sub-characteristics:
   a) Co-existence
      - Works alongside other software
      
   b) Interoperability
      - Exchange data with other systems

   Test Approach:
   âœ“ Integration testing
   âœ“ API testing
   âœ“ Cross-platform testing
   
   Example Tests:
   - Works with all major browsers
   - API integration with payment gateway
   - Runs on Windows, Mac, Linux

4. USABILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Ease of use and learnability

   Sub-characteristics:
   a) Appropriateness Recognizability
      - Users understand if suitable for needs
      
   b) Learnability
      - Easy to learn
      
   c) Operability
      - Easy to operate and control
      
   d) User Error Protection
      - Protects against errors
      
   e) User Interface Aesthetics
      - Pleasing interface
      
   f) Accessibility
      - Usable by people with disabilities

   Test Approach:
   âœ“ Usability testing
   âœ“ User acceptance testing
   âœ“ Accessibility testing (WCAG)
   
   Example Tests:
   - First-time users complete task in <5 min
   - Keyboard navigation works
   - Screen reader compatible
   - Error messages are clear

5. RELIABILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   System performs under stated conditions

   Sub-characteristics:
   a) Maturity
      - Meets reliability needs under normal use
      
   b) Availability
      - Operational when needed
      
   c) Fault Tolerance
      - Operates despite faults
      
   d) Recoverability
      - Recovers data after failure

   Test Approach:
   âœ“ Reliability testing
   âœ“ Failover testing
   âœ“ Recovery testing
   âœ“ Long-running tests
   
   Example Tests:
   - 99.9% uptime
   - Automatic failover to backup server
   - Recover from database crash in <5 min
   - No data loss on unexpected shutdown

6. SECURITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Protection of information and data

   Sub-characteristics:
   a) Confidentiality
      - Data accessible only to authorized
      
   b) Integrity
      - Data not modified without authorization
      
   c) Non-repudiation
      - Actions can be proven
      
   d) Accountability
      - Actions traced to entity
      
   e) Authenticity
      - Identity verified

   Test Approach:
   âœ“ Security testing
   âœ“ Penetration testing
   âœ“ Vulnerability scanning
   âœ“ Authentication/authorization testing
   
   Example Tests:
   - SQL injection attempts blocked
   - XSS attacks prevented
   - Unauthorized access denied
   - Passwords encrypted
   - Audit logs created

7. MAINTAINABILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Ease of modification

   Sub-characteristics:
   a) Modularity
      - Components independent
      
   b) Reusability
      - Components reusable
      
   c) Analyzability
      - Easy to diagnose issues
      
   d) Modifiability
      - Easy to modify
      
   e) Testability
      - Easy to test

   Test Approach:
   âœ“ Code reviews
   âœ“ Static analysis
   âœ“ Architecture reviews
   âœ“ Test coverage analysis
   
   Example Tests:
   - Code coverage >80%
   - Cyclomatic complexity <10
   - No code duplication >10 lines
   - Unit test execution time <5 sec

8. PORTABILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Ease of transfer to different environments

   Sub-characteristics:
   a) Adaptability
      - Adapts to different environments
      
   b) Installability
      - Easy to install/uninstall
      
   c) Replaceability
      - Can replace another system

   Test Approach:
   âœ“ Installation testing
   âœ“ Cross-platform testing
   âœ“ Migration testing
   
   Example Tests:
   - Install on Windows, Mac, Linux
   - Uninstall leaves no traces
   - Migrate data from old system
   - Works on different cloud providers

QUALITY IN USE MODEL (5 Characteristics):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Measured from user's perspective in real context

1. Effectiveness
   - Accuracy and completeness of goals

2. Efficiency
   - Resources expended relative to goals

3. Satisfaction
   - User fulfillment of needs

4. Freedom from Risk
   - Mitigates economic, health, environmental risk

5. Context Coverage
   - Works in specified contexts

PRACTICAL APPLICATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Example: E-commerce Website Quality Requirements
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Quality Character.  â”‚ Requirement & Test Criteria      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Functional Suit.    â”‚ - All checkout features work     â”‚
â”‚                     â”‚ - 100% user stories implemented  â”‚
â”‚                     â”‚ Test: Functional test coverage   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Performance         â”‚ - Page load <2 sec               â”‚
â”‚                     â”‚ - Support 5000 concurrent users  â”‚
â”‚                     â”‚ Test: JMeter load testing        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Compatibility       â”‚ - Works on Chrome, Safari, etc.  â”‚
â”‚                     â”‚ - Mobile responsive              â”‚
â”‚                     â”‚ Test: Cross-browser testing      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Usability           â”‚ - First-time users complete      â”‚
â”‚                     â”‚   purchase in <3 min             â”‚
â”‚                     â”‚ Test: Usability testing          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Reliability         â”‚ - 99.9% uptime                   â”‚
â”‚                     â”‚ - Zero data loss                 â”‚
â”‚                     â”‚ Test: Stress & failover tests    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Security            â”‚ - PCI DSS compliant              â”‚
â”‚                     â”‚ - HTTPS enforced                 â”‚
â”‚                     â”‚ Test: Penetration testing        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Maintainability     â”‚ - Code coverage >85%             â”‚
â”‚                     â”‚ - Automated regression suite     â”‚
â”‚                     â”‚ Test: Static analysis            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Portability         â”‚ - Runs on AWS, Azure, GCP        â”‚
â”‚                     â”‚ - Docker containerized           â”‚
â”‚                     â”‚ Test: Deployment testing         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CREATING QUALITY METRICS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For each characteristic, define:
1. Measurement method
2. Target value
3. Acceptance criteria

Example (Performance Efficiency):
```
Characteristic: Performance Efficiency
Sub-characteristic: Time Behavior
Metric: Average response time

Measurement Method:
- Automated performance test using JMeter
- 1000 concurrent users
- 10-minute test duration
- Measure avg response time for all API calls

Target Value: <500ms
Acceptance Criteria: <800ms

Results:
API Endpoint           | Avg Response Time | Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET /products         | 320ms             | âœ“ Pass
POST /checkout        | 450ms             | âœ“ Pass
GET /orders           | 280ms             | âœ“ Pass
POST /payment         | 650ms             | âœ“ Pass

Overall: PASS (all <800ms)
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ISTQB Guidelines & Certification

### 3.1 ISTQB Overview

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ISTQB: INTERNATIONAL SOFTWARE TESTING
       QUALIFICATIONS BOARD
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Overview:
World's leading certification scheme for software testers
Established: 2002
Member Boards: 60+ countries
Certifications Issued: 900,000+ worldwide

MISSION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Standardize software testing education and certification globally

Benefits:
âœ“ Common terminology
âœ“ Standard testing approaches
âœ“ Professional recognition
âœ“ Career advancement
âœ“ Improved testing quality

ISTQB CERTIFICATION STRUCTURE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Three Levels:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  EXPERT LEVEL   â”‚ (3+ years exp)
                    â”‚   - Test Mgmt   â”‚
                    â”‚   - Improvement â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ADVANCED LEVEL â”‚ (2+ years exp)
                    â”‚   - Test Managerâ”‚
                    â”‚   - Test Analystâ”‚
                    â”‚   - Tech Analystâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ FOUNDATION LEVELâ”‚ (No prerequisites)
                    â”‚   - Core Testingâ”‚
                    â”‚   - Agile Testerâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FOUNDATION LEVEL (CTFL):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Certified Tester Foundation Level (CTFL)

Target Audience:
- New to testing
- Career changers
- Anyone working with testers
- Non-QA roles wanting testing knowledge

Exam Details:
Format: Multiple choice
Questions: 40
Duration: 60 minutes
Passing Score: 65% (26/40 correct)
Prerequisites: None
Cost: $200-300 (varies by country)
Validity: Lifetime

SYLLABUS STRUCTURE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Chapter 1: Fundamentals of Testing (175 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Topics:
âœ“ What is testing?
âœ“ Why is testing necessary?
âœ“ Seven testing principles
âœ“ Test process
âœ“ Psychology of testing

Key Concepts:
- Testing shows presence of defects, not absence
- Exhaustive testing is impossible
- Early testing saves time and money
- Defects cluster together
- Pesticide paradox
- Testing is context-dependent
- Absence-of-errors fallacy

Example Question:
"Which of the following is NOT one of the seven testing principles?
a) Early testing
b) Defect clustering
c) 100% test coverage is achievable
d) Testing is context dependent"

Answer: c) 100% test coverage is NOT a principle
(Exhaustive testing is impossible is the actual principle)

Chapter 2: Testing Throughout SDLC (100 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Topics:
âœ“ Software development lifecycle models
âœ“ Test levels
âœ“ Test types
âœ“ Maintenance testing

Test Levels:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Level           â”‚ Focus                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Component       â”‚ Individual units/modules         â”‚
â”‚ (Unit) Testing  â”‚ Typically by developers          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Integration     â”‚ Interfaces between components    â”‚
â”‚ Testing         â”‚ Component interactions           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ System Testing  â”‚ Complete system behavior         â”‚
â”‚                 â”‚ End-to-end scenarios             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Acceptance      â”‚ System ready for delivery        â”‚
â”‚ Testing (UAT)   â”‚ User/customer validates          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Test Types:
- Functional Testing
- Non-functional Testing (performance, usability, security)
- White-box Testing
- Change-related Testing (confirmation, regression)

Chapter 3: Static Testing (80 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Topics:
âœ“ Static testing basics
âœ“ Review process
âœ“ Review types

Reviews vs Dynamic Testing:
Static (Reviews): Find defects in documents/code without execution
Dynamic (Testing): Find defects by executing code

Review Types:
1. Informal Review (Ad-hoc)
2. Walkthrough (Led by author)
3. Technical Review (Technical experts)
4. Inspection (Formal, moderator-led)

Formal Review Process:
Planning â†’ Kick-off â†’ Individual Review â†’
Review Meeting â†’ Rework â†’ Follow-up

Chapter 4: Test Techniques (330 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Topics:
âœ“ Black-box test techniques
âœ“ White-box test techniques
âœ“ Experience-based test techniques

Black-Box Techniques:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Equivalence Partitioning (EP)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Example: Age field (18-65)
Partitions:
- Below min: <18 (Invalid)
- Valid range: 18-65 (Valid)
- Above max: >65 (Invalid)

Test Cases:
TC1: Age = 17 (Invalid)
TC2: Age = 30 (Valid)
TC3: Age = 66 (Invalid)

2. Boundary Value Analysis (BVA)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Test at boundaries (edges of partitions)

Example: Age field (18-65)
Boundary Values:
- 17 (just below minimum)
- 18 (minimum valid)
- 19 (just above minimum)
- 64 (just below maximum)
- 65 (maximum valid)
- 66 (just above maximum)

Test Cases: 17, 18, 19, 64, 65, 66

3. Decision Table Testing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For complex business rules with multiple conditions

Example: Discount calculation
Rules:
- VIP customer + Order >$100 = 20% discount
- VIP customer + Order <$100 = 10% discount
- Non-VIP + Order >$100 = 5% discount
- Non-VIP + Order <$100 = No discount

Decision Table:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Condition     â”‚ Rule1 â”‚ Rule2 â”‚ Rule3 â”‚ Rule4 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ VIP Customer  â”‚  Yes  â”‚  Yes  â”‚  No   â”‚  No   â”‚
â”‚ Order >$100   â”‚  Yes  â”‚  No   â”‚  Yes  â”‚  No   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Discount      â”‚  20%  â”‚  10%  â”‚  5%   â”‚  0%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

4 test cases (one per rule)

4. State Transition Testing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For systems with different states

Example: Login system
States: Logged Out, 1st Attempt, 2nd Attempt, Locked
Events: Valid login, Invalid login

State Diagram:
Logged Out --(Invalid)-> 1st Attempt --(Invalid)->
2nd Attempt --(Invalid)-> Locked

Tests:
- Valid login from Logged Out â†’ Success
- 3 invalid logins â†’ Account locked
- etc.

White-Box Technique:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Statement Coverage:
% of executable statements tested

Example Code:
```
if (x > 0) {
    print("Positive");  // Statement 1
}
print("Done");         // Statement 2
```

Test: x = 5
Executes: Statements 1 and 2
Coverage: 100%

Decision Coverage:
% of decision outcomes tested

Same code:
Decisions: (x > 0) can be True or False
Need 2 tests:
- x = 5 (True branch)
- x = -1 (False branch)

Experience-Based:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Error Guessing:
Based on tester's experience and intuition

Exploratory Testing:
Simultaneous learning, test design, and execution

Chapter 5: Test Management (225 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Topics:
âœ“ Test organization
âœ“ Test planning & estimation
âœ“ Test monitoring & control
âœ“ Configuration management
âœ“ Risk and testing
âœ“ Defect management

Test Pyramid:
         /\
        /UI\        10% - End-to-end tests
       /â”€â”€â”€â”€\
      /Service\     30% - Integration/API tests
     /â”€â”€â”€â”€â”€â”€â”€â”€\
    /   Unit   \    60% - Unit tests
   /â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\

Entry Criteria (to start testing):
âœ“ Test environment ready
âœ“ Test data available
âœ“ Build stable
âœ“ Test cases reviewed

Exit Criteria (to stop testing):
âœ“ All test cases executed
âœ“ X% pass rate achieved
âœ“ No critical defects open
âœ“ Coverage targets met

Chapter 6: Tool Support for Testing (40 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Topics:
âœ“ Test tool categories
âœ“ Tool selection
âœ“ Tool lifecycle

Tool Types:
- Test Management: TestRail, Zephyr
- Defect Tracking: Jira, Bugzilla
- Test Automation: Selenium, Cypress
- Performance: JMeter, LoadRunner
- Static Analysis: SonarQube, ESLint

EXAM PREPARATION TIPS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Study Plan (6-8 weeks):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Week 1-2: Chapters 1-2 (Fundamentals + SDLC)
Week 3: Chapter 3 (Static Testing)
Week 4-5: Chapter 4 (Test Techniques) - Most important
Week 6: Chapter 5 (Test Management)
Week 7: Chapter 6 + Mock Exams
Week 8: Final review + Mock Exams

Study Resources:
âœ“ ISTQB Syllabus (Free download)
âœ“ ISTQB Glossary (terminology)
âœ“ Sample exams (practice questions)
âœ“ Study guides (books, online courses)
âœ“ Practice, practice, practice

Sample Exam Question Formats:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Type 1: Definition
"What is exploratory testing?
a) Testing without test cases
b) Simultaneous learning, design, and execution
c) Random testing
d) Ad-hoc testing by end users"

Answer: b)

Type 2: Application
"Age field accepts 18-65. Using BVA, which test values are correct?
a) 17, 18, 65, 66
b) 18, 19, 64, 65
c) 1, 18, 40, 65, 99
d) 17, 18, 19, 64, 65, 66"

Answer: d) (all boundary values)

Type 3: Scenario
"You have 100 test cases. After 1 week: 80 executed, 60 passed,
15 failed, 5 blocked. What's the pass rate?
a) 60%
b) 75%
c) 80%
d) 100%"

Answer: b) 75% (60 passed / 80 executed)

ADVANCED LEVEL:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Three Streams:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Test Manager
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For: Test leads, managers
Focus: Team management, planning, metrics
Prerequisites: Foundation + 18 months experience
Exam: 65 questions, 180 minutes, 65% pass

Topics:
- Test management process
- Test estimation
- Metrics and reporting
- Distributed testing
- People and team dynamics

2. Test Analyst
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For: QA analysts, testers
Focus: Black-box techniques, test design
Prerequisites: Foundation + 18 months experience
Exam: 60 questions, 180 minutes, 65% pass

Topics:
- Testing process (analyst perspective)
- Test techniques (detailed)
- Testing software quality characteristics
- Reviews
- Defect management

3. Technical Test Analyst
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For: Technical testers, SDETs
Focus: White-box techniques, automation
Prerequisites: Foundation + 18 months experience
Exam: 45 questions, 180 minutes, 65% pass

Topics:
- Risk-based testing
- White-box test techniques
- Static analysis
- Security testing
- Performance testing

SPECIALIST CERTIFICATIONS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Agile Testing:
- Agile Tester Foundation
- Agile Technical Tester

Other Specialists:
- Test Automation Engineer
- Performance Tester
- Security Tester
- Mobile Application Tester
- Usability Tester
- AI Testing

BENEFITS OF ISTQB CERTIFICATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Professional:
âœ“ Industry recognition
âœ“ Career advancement
âœ“ Salary increase (10-20% average)
âœ“ Job opportunities
âœ“ Global mobility

Personal:
âœ“ Structured learning
âœ“ Confidence boost
âœ“ Common language with peers
âœ“ Best practices knowledge

Organizational:
âœ“ Standardized skills
âœ“ Quality improvement
âœ“ Competitive advantage
âœ“ Client confidence

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Test Process Improvement Models

### 4.1 TMMi (Test Maturity Model Integration)

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TMMi: TEST MATURITY MODEL INTEGRATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose:
Framework for test process improvement and assessment

Developed: TMMi Foundation (2008)
Based on: CMMI (Capability Maturity Model Integration)

CONCEPT: MATURITY LEVELS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Organizations progress through 5 maturity levels

LEVEL 1: INITIAL (Chaotic)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Characteristics:
âœ— Ad-hoc, chaotic testing
âœ— No defined process
âœ— Success depends on individuals
âœ— Testing often combined with debugging
âœ— No test planning
âœ— Reactive approach

Typical Issues:
- "We'll test when development is done"
- No test documentation
- Testing as afterthought
- High defect leakage

How It Looks:
Developer: "I'm done coding, can you test?"
Tester: "Sure, what should I test?"
Developer: "Um, just click around and see if it breaks"
Result: Bugs found in production

To Move to Level 2:
âœ“ Establish basic test processes
âœ“ Document test approach
âœ“ Create test plans
âœ“ Track defects systematically

LEVEL 2: MANAGED (Organized)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Characteristics:
âœ“ Testing is planned
âœ“ Test policy and strategy exist
âœ“ Testing independent from development
âœ“ Basic test techniques used
âœ“ Defects tracked and managed

Process Areas (4):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Test Policy and Strategy
   - Organization-wide test policy
   - Test strategy defined
   - Commitment to testing

2. Test Planning
   - Test plans for each project
   - Scope, approach, resources defined
   - Schedule created

3. Test Monitoring and Control
   - Track test progress
   - Measure against plan
   - Take corrective action

4. Test Design and Execution
   - Test cases designed from requirements
   - Test execution logged
   - Results recorded

Example Practices:
```
BEFORE (Level 1):
No test plan, ad-hoc testing

AFTER (Level 2):
Test Plan created:
- Scope: Login and checkout modules
- Approach: Manual functional testing
- Resources: 2 testers, 2 weeks
- Test cases: 100 cases documented in Excel
- Defects: Tracked in Jira
```

To Move to Level 3:
âœ“ Integrate testing into SDLC
âœ“ Establish test organization
âœ“ Define standard test processes
âœ“ Train testing team

LEVEL 3: DEFINED (Standardized)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Characteristics:
âœ“ Testing fully integrated into SDLC
âœ“ Standardized test processes
âœ“ Test organization established
âœ“ Test training program
âœ“ Non-functional testing introduced
âœ“ Peer reviews conducted

Process Areas (9 total, adding 5):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

5. Test Organization
   - Independent test team
   - Clear roles and responsibilities
   - Career paths for testers

6. Test Training Program
   - Identify training needs
   - Provide training
   - Track competencies

7. Test Lifecycle and Integration
   - Testing activities for each SDLC phase
   - Entry/exit criteria
   - Test deliverables defined

8. Non-Functional Testing
   - Performance testing
   - Security testing
   - Usability testing
   - Reliability testing

9. Peer Reviews
   - Requirements reviews
   - Test plan reviews
   - Test case reviews
   - Formal review process

Example Organization:
```
QA ORGANIZATION CHART (Level 3)

QA Director
    â”œâ”€â”€ Test Manager (Web)
    â”‚   â”œâ”€â”€ Senior Test Analysts (3)
    â”‚   â””â”€â”€ Test Analysts (5)
    â”œâ”€â”€ Test Manager (Mobile)
    â”‚   â”œâ”€â”€ Senior Test Analysts (2)
    â”‚   â””â”€â”€ Test Analysts (3)
    â””â”€â”€ Automation Lead
        â”œâ”€â”€ Automation Engineers (4)
        â””â”€â”€ Performance Tester (1)

Training Program:
- All testers: ISTQB Foundation
- Senior: ISTQB Advanced
- Automation: Selenium certification
- Annual training budget: $50K
```

To Move to Level 4:
âœ“ Establish test measurement program
âœ“ Implement quality evaluation
âœ“ Advanced reviews
âœ“ Product quality assessment

LEVEL 4: MEASURED (Quantitative)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Characteristics:
âœ“ Testing is measured and quantified
âœ“ Test process metrics defined
âœ“ Product quality evaluated
âœ“ Advanced peer reviews
âœ“ Data-driven decisions

Process Areas (13 total, adding 4):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

10. Test Measurement
    - Define test metrics
    - Collect and analyze data
    - Report metrics
    - Use for improvement

11. Product Quality Evaluation
    - Assess product quality
    - Quality criteria defined
    - Quality gates
    - Go/no-go decisions based on data

12. Advanced Reviews
    - Formal inspection process
    - Quantitative review goals
    - Review metrics tracked
    - Continuous review improvement

13. Test Design and Execution (Advanced)
    - Advanced test techniques
    - Test optimization
    - Traceability

Example Metrics Dashboard:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MONTHLY QA METRICS REPORT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Test Execution:
- Test cases executed: 2,450
- Pass rate: 94% (Target: 95%)
- Automation coverage: 65% (Target: 70%)

Quality Metrics:
- Defect density: 2.3 per 1000 LOC (Target: <3.0) âœ“
- DRE: 96% (Target: >95%) âœ“
- Defect leakage: 4% (Target: <5%) âœ“
- Escaped defects: 3 (Target: <5) âœ“

Process Metrics:
- Test preparation time: 25% of total
- Test execution time: 60%
- Defect fixing time: 15%

Trend Analysis:
Month  | Defects Found | Pass Rate | DRE
Jan    | 87           | 92%       | 94%
Feb    | 65           | 93%       | 95%
Mar    | 52           | 94%       | 96%
Trend: â†‘ Improving

Quality Gate Status: PASS âœ“
Recommendation: Approve Release
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

To Move to Level 5:
âœ“ Defect prevention programs
âœ“ Quality control
âœ“ Test process optimization
âœ“ Continuous improvement culture

LEVEL 5: OPTIMIZING (Continuous Improvement)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Characteristics:
âœ“ Continuous process improvement
âœ“ Defect prevention focus
âœ“ Quality control
âœ“ Test process optimization
âœ“ Innovation and automation
âœ“ Industry leadership

Process Areas (16 total, adding 3):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

14. Defect Prevention
    - Root cause analysis
    - Prevent defect recurrence
    - Proactive quality

15. Quality Control
    - Statistical process control
    - Quality trends analyzed
    - Predictive quality models

16. Test Process Optimization
    - Continuous improvement
    - Technology innovation
    - Process efficiency
    - Return on investment

Example Improvement Initiative:
```
DEFECT PREVENTION PROGRAM

Problem Identified:
30% of defects are in data validation across multiple projects

Root Cause Analysis:
- Developers not aware of validation rules
- No standard validation library
- Each team implements differently

Prevention Actions:
1. Created centralized validation library (reusable)
2. Code review checklist includes validation check
3. Developer training on validation best practices
4. Automated static analysis rules for validation

Results (6 months):
- Validation defects: 30% â†’ 8% (73% reduction)
- Development time saved: 15% (no rework)
- ROI: 5:1 (investment vs savings)

Continuous Monitoring:
- Monthly defect analysis by category
- Quarterly review of prevention effectiveness
- Annual update of prevention strategies
```

TMMi ASSESSMENT:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Assessment Process:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Preparation (2-4 weeks)
   - Scope definition
   - Team formation
   - Documentation review

2. On-site Assessment (1-2 weeks)
   - Interviews
   - Document review
   - Process observation
   - Evidence collection

3. Reporting (2 weeks)
   - Gap analysis
   - Maturity level determination
   - Recommendations
   - Improvement roadmap

4. Follow-up (Ongoing)
   - Implement improvements
   - Monitor progress
   - Re-assessment (annually)

Assessment Ratings:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For each process area:
- Not Achieved
- Partially Achieved
- Largely Achieved
- Fully Achieved

Example Assessment Result:
```
TMMi ASSESSMENT REPORT
Organization: ACME Corp
Current Maturity Level: 2 (Managed)

Level 2 Process Areas:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Process Area              â”‚ Rating          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Test Policy & Strategy    â”‚ Fully Achieved  â”‚
â”‚ Test Planning             â”‚ Largely Achievedâ”‚
â”‚ Test Monitoring & Control â”‚ Fully Achieved  â”‚
â”‚ Test Design & Execution   â”‚ Largely Achievedâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Strengths:
âœ“ Well-defined test policy
âœ“ Consistent test planning
âœ“ Good defect tracking

Gaps for Level 3:
âœ— No formal test organization structure
âœ— Limited test training program
âœ— Non-functional testing ad-hoc
âœ— Peer reviews not systematic

Recommended Actions:
1. Establish dedicated QA team (Priority: High)
2. Implement training program (Priority: High)
3. Define non-functional test processes (Priority: Medium)
4. Formalize review process (Priority: Medium)

Timeline to Level 3: 12-18 months
```

BENEFITS OF TMMi:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Quantifiable Benefits:
âœ“ 15-30% reduction in defects
âœ“ 20-40% reduction in testing costs
âœ“ 10-25% faster time to market
âœ“ ROI: 3:1 to 8:1 within 2 years

Qualitative Benefits:
âœ“ Improved test process consistency
âœ“ Better test team capability
âœ“ Enhanced product quality
âœ“ Customer satisfaction
âœ“ Competitive advantage
âœ“ Industry recognition (if certified)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

### 4.2 Other Process Improvement Models

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ALTERNATIVE TEST IMPROVEMENT MODELS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TPI NEXT (TEST PROCESS IMPROVEMENT)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Overview:
Business-driven test process improvement model
Developed by Sogeti (part of Capgemini)

Key Concept: Improvement based on business goals

Structure:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

16 Key Areas organized in 3 clusters:

1. Stakeholder Cluster:
   - Stakeholder Commitment
   - Degree of Involvement
   - Test Strategy
   - Test Organization

2. Core Cluster (Test Process):
   - Test Management
   - Estimating & Planning
   - Metrics
   - Defect Management
   - Testware Management
   - Test Methodology
   - Tester Professionalism
   - Test Case Design

3. Supporting Cluster:
   - Test Tools
   - Test Environment
   - Office Environment
   - Communication

Maturity Levels (per key area):
A - Initial
B - Controlled
C - Efficient
D - Optimizing

Example: Test Strategy
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Level A (Initial):
No test strategy, ad-hoc approach

Level B (Controlled):
Test strategy exists, documented, communicated

Level C (Efficient):
Risk-based test strategy, measurable, optimized

Level D (Optimizing):
Continuous improvement, industry benchmark, innovation

Unique Features:
âœ“ Flexible (can improve specific areas)
âœ“ Business-driven prioritization
âœ“ Modular improvement
âœ“ Quick assessment

STEP (SYSTEMATIC TEST AND EVALUATION PROCESS)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Overview:
Structured framework by William Perry
Focus: Systematic testing approach

12-Step Process:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase I: Establish Perspective
Step 1: Assess Development Environment
Step 2: Develop Test Plan
Step 3: Test Factor Analysis

Phase II: Plan Tests
Step 4: Test Transaction Flow
Step 5: Develop Test Matrices
Step 6: Develop Test Scripts

Phase III: Execute and Record Tests
Step 7: Execute Tests
Step 8: Conduct Change Control
Step 9: Confirm Test Results

Phase IV: Evaluate Testing
Step 10: Conduct Posttest Meeting
Step 11: Compile Test Metrics
Step 12: Refine Testing Process

Benefits:
âœ“ Structured approach
âœ“ Comprehensive
âœ“ Includes test planning
âœ“ Focus on measurement

CTP (CRITICAL TESTING PROCESSES)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Overview:
Focus on 12 critical testing processes
By Rex Black

12 Critical Processes:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Test Policy (Organizational)
2. Test Strategy
3. Test Organization
4. Test Training
5. Test Plan (Project)
6. Risk-Based Testing
7. Test Environment
8. Test Data
9. Requirements, Design, Code Reviews
10. Test Design
11. Test Development
12. Test Execution, Defect Reporting, Tracking

Improvement Approach:
1. Assess current state (survey)
2. Identify weaknesses
3. Prioritize improvements
4. Implement changes
5. Measure effectiveness

Benefits:
âœ“ Focused on critical areas
âœ“ Practical, actionable
âœ“ Industry best practices
âœ“ Flexible implementation

COMPARISON OF MODELS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model     â”‚Complexityâ”‚ Scope    â”‚ Rigidityâ”‚ Cost    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TMMi      â”‚ High    â”‚ Complete â”‚ Rigid   â”‚ High    â”‚
â”‚ TPI NEXT  â”‚ Medium  â”‚ Complete â”‚ Flexibleâ”‚ Medium  â”‚
â”‚ STEP      â”‚ Medium  â”‚ Process  â”‚ Medium  â”‚ Low     â”‚
â”‚ CTP       â”‚ Low     â”‚ Focused  â”‚ Flexibleâ”‚ Low     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SELECTION CRITERIA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Choose TMMi if:
âœ“ Large organization
âœ“ Need formal certification
âœ“ Comprehensive improvement needed
âœ“ Long-term commitment
âœ“ Budget available

Choose TPI NEXT if:
âœ“ Medium-large organization
âœ“ Business-driven priorities
âœ“ Flexible approach preferred
âœ“ Targeted improvements
âœ“ Agile-friendly

Choose STEP if:
âœ“ Structured process needed
âœ“ Small-medium organization
âœ“ Focus on systematic testing
âœ“ Limited budget

Choose CTP if:
âœ“ Quick start needed
âœ“ Focus on critical areas
âœ“ Practical, actionable guidance
âœ“ Small team
âœ“ Limited resources

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---
## Agile & DevOps Best Practices

### 5.1 Agile Testing Best Practices

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
AGILE TESTING BEST PRACTICES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

AGILE TESTING PRINCIPLES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. WHOLE TEAM APPROACH:
   Testing is everyone's responsibility
   
   Traditional Model:
   Developer writes code â†’ Throws over wall â†’ QA tests
   Problem: Late defect discovery, finger-pointing
   
   Agile Model:
   Whole team owns quality
   - Developers write unit tests
   - QA guides testing strategy
   - Product Owner defines acceptance criteria
   - Everyone participates in testing
   
   Benefits:
   âœ“ Earlier defect detection
   âœ“ Shared quality ownership
   âœ“ Better collaboration
   âœ“ Faster feedback loops

2. EARLY AND CONTINUOUS TESTING:
   Test from Day 1, not at the end
   
   Sprint Timeline:
   Day 1: Testing involvement in planning
   Day 2-5: Testing in parallel with development
   Day 6-8: Exploratory testing, edge cases
   Day 9-10: Regression, UAT
   
   Not: Development (Days 1-8) â†’ Testing (Days 9-10)

3. SHIFT LEFT TESTING:
   Move testing activities earlier in SDLC
   
   Traditional:
   Requirements â†’ Design â†’ Code â†’ Test (late)
   
   Shift Left:
   Requirements (+ Test Scenarios) â†’ Design (+ Test Cases) â†’ 
   Code (+ Unit Tests) â†’ Test (+ Integration/System Tests)
   
   Activities:
   âœ“ Review requirements for testability
   âœ“ Create test scenarios during planning
   âœ“ Design test cases before coding starts
   âœ“ Automate tests as code is developed
   âœ“ Continuous integration and testing

4. TEST AUTOMATION:
   Automate repetitive tests for fast feedback
   
   Test Pyramid:
              /\
             /UI\        10% - E2E/UI tests (slow, brittle)
            /â”€â”€â”€â”€\
           /  API \      30% - API/Integration tests
          /â”€â”€â”€â”€â”€â”€â”€â”€\
         /   Unit   \    60% - Unit tests (fast, stable)
        /â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\
   
   Focus: More unit tests, fewer UI tests
   Why: Unit tests are fast, stable, easy to maintain

5. CONTINUOUS FEEDBACK:
   Provide rapid feedback to team
   
   Feedback Loops:
   - Unit tests: Seconds (developer feedback)
   - API tests: Minutes (integration feedback)
   - UI tests: Hours (end-to-end feedback)
   - Manual exploratory: Daily (usability feedback)
   
   CI/CD Pipeline:
   Code Commit â†’ Build â†’ Unit Tests â†’ Integration Tests â†’ 
   Deploy to Test Env â†’ Smoke Tests â†’ Full Regression â†’ 
   Deploy to Staging â†’ UAT â†’ Production
   
   Fast failure = Fast fix

AGILE TESTING QUADRANTS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Framework by Lisa Crispin & Janet Gregory

              Supporting the Team  |  Critique Product
                                  |
                     Q2           |        Q3
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                   |                  â”‚
              â”‚ Functional Tests  | Exploratory     â”‚
              â”‚ Story Tests       | Scenario Testingâ”‚
Business-     â”‚ Prototypes        | UAT             â”‚
Facing        â”‚ Simulations       | Usability       â”‚
              â”‚                   |                  â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚                   |                  â”‚
Technology-   â”‚ Unit Tests        | Performance     â”‚
Facing        â”‚ Component Tests   | Load/Stress     â”‚
              â”‚ API Tests         | Security        â”‚
              â”‚ (Automated)       | (Tools)         â”‚
              â”‚                   |                  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     Q1           |        Q4
                                  |
              Automated          |  Manual + Tools

QUADRANT 1 (Q1): Technology-Facing, Supporting Team
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Guide development, prevent defects
When: During development (TDD approach)

Tests:
- Unit Tests (developers)
- Component Tests (developers + QA)
- API Tests (QA + developers)

Example (Unit Test - Python):
```python
def test_calculate_discount():
    # Test VIP customer with order > $100
    result = calculate_discount(customer_type="VIP", order_total=150)
    assert result == 30.0  # 20% discount = $30
    
    # Test regular customer
    result = calculate_discount(customer_type="Regular", order_total=150)
    assert result == 7.5   # 5% discount = $7.50
```

Automation: 100% automated
Tools: pytest, JUnit, NUnit, Jest
Who: Primarily developers, with QA guidance

QUADRANT 2 (Q2): Business-Facing, Supporting Team
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Validate functional behavior, acceptance criteria
When: During and after development

Tests:
- Functional Tests
- Story/Feature Tests
- BDD Scenarios
- Example-based tests

Example (BDD - Gherkin):
```gherkin
Feature: Shopping Cart Checkout

Scenario: Successful checkout with valid payment
  Given user has items in shopping cart
  And user is on checkout page
  When user enters valid credit card details
  And clicks "Place Order"
  Then order should be created successfully
  And user should see order confirmation
  And confirmation email should be sent
```

Automation: 70-80% automated
Tools: Cucumber, SpecFlow, Robot Framework, Selenium
Who: QA + Developers + Product Owner (write scenarios)

QUADRANT 3 (Q3): Business-Facing, Critique Product
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Evaluate product quality, user experience
When: After development, before release

Tests:
- Exploratory Testing
- Usability Testing
- User Acceptance Testing (UAT)
- Beta Testing

Example Session Charter:
```
EXPLORATORY TESTING SESSION

Mission: Test checkout flow for edge cases
Time: 90 minutes
Areas: Payment, Order confirmation, Email notifications

Personas:
- International user
- User with slow internet
- Mobile user
- First-time buyer

Findings:
âœ“ Payment timeout for slow connections (BUG-567)
âœ“ Confusing error message for declined cards (UX-123)
âœ“ Success, but email delayed 5 minutes (BUG-568)
```

Automation: 10-20% (can't fully automate creativity)
Tools: Session-based test management, mind maps
Who: QA (primarily), some developers

QUADRANT 4 (Q4): Technology-Facing, Critique Product
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Purpose: Validate non-functional requirements
When: After development, continuous monitoring

Tests:
- Performance Testing
- Load/Stress Testing
- Security Testing
- Scalability Testing
- Compatibility Testing

Example (JMeter Load Test):
```
Test Plan: Checkout Load Test

Configuration:
- Users: 1000 concurrent
- Ramp-up: 60 seconds
- Duration: 10 minutes

Scenarios:
1. Browse products (40%)
2. Add to cart (30%)
3. Checkout (20%)
4. Search (10%)

Success Criteria:
âœ“ Response time < 2 seconds (95th percentile)
âœ“ Error rate < 1%
âœ“ Throughput > 100 requests/second
```

Automation: 90% automated (tools-based)
Tools: JMeter, LoadRunner, OWASP ZAP, Burp Suite
Who: Performance/Security specialists + QA

AGILE TEST STRATEGY:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Sprint Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DAY 0 (Sprint Planning):
- QA reviews user stories
- Identifies testability issues
- Creates test scenarios
- Estimates testing effort
- Defines acceptance criteria (with PO)

Output: Test plan for sprint, DoD agreed

DAY 1-2 (Early Sprint):
- Developers write unit tests (TDD)
- QA creates detailed test cases
- QA prepares test data
- QA sets up test environment
- Automation framework ready

Output: Test cases ready, environment ready

DAY 3-7 (Mid Sprint):
- Developers complete features
- QA tests completed features immediately
- Regression tests run continuously (CI/CD)
- Bugs logged and fixed quickly
- Pair testing (QA + Dev)

Output: Features tested, bugs fixed

DAY 8-9 (Late Sprint):
- Exploratory testing
- Edge case testing
- UAT with Product Owner
- Final regression
- Performance smoke tests

Output: Sprint tested, ready for demo

DAY 10 (Sprint End):
- Sprint demo
- Retrospective (what to improve)
- Update test documentation
- Archive test results

Output: Sprint deliverable, lessons learned

DEFINITION OF DONE (DoD):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

A user story is "Done" when:

Code Complete:
âœ“ Code written and peer-reviewed
âœ“ Unit tests written (>80% coverage)
âœ“ Code merged to main branch
âœ“ No compiler warnings

Testing Complete:
âœ“ All acceptance criteria tested
âœ“ Functional tests passed
âœ“ Regression tests passed
âœ“ No critical/high bugs open
âœ“ Exploratory testing completed

Documentation Complete:
âœ“ Code documented (inline comments)
âœ“ API documentation updated
âœ“ User documentation updated (if needed)
âœ“ Test cases documented

Deployment Ready:
âœ“ Deployed to test environment
âœ“ Smoke tests passed
âœ“ Product Owner acceptance obtained

Example Checklist:
```
USER STORY: US-234 - Add "Forgot Password" feature

âœ… Code written and reviewed
âœ… Unit tests: 15 tests, 85% coverage
âœ… Functional tests: 8 test cases (all passed)
âœ… Regression: 500 tests (498 passed, 2 unrelated failures)
âœ… Exploratory testing: 2 hours (no critical issues)
âœ… Security testing: Password reset token secure
âœ… Email template reviewed and approved
âœ… Zero critical bugs, 1 minor bug (deferred)
âœ… PO acceptance: Approved by Jane (2024-01-10)
âœ… Deployed to staging, smoke tests passed

Status: DONE âœ…
```

AGILE TESTING CHALLENGES & SOLUTIONS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Challenge 1: Short Iterations, Not Enough Time
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem: 2-week sprint, feature complete Day 8, only 2 days to test

Solutions:
âœ“ Test in parallel with development (not after)
âœ“ Automate regression tests (run continuously)
âœ“ Focus on risk-based testing (test critical first)
âœ“ Involve QA in planning (testability input)
âœ“ Test early builds (don't wait for "done")

Challenge 2: Changing Requirements
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem: Requirements change mid-sprint, tests become obsolete

Solutions:
âœ“ Embrace change (it's agile)
âœ“ Keep test cases modular (easy to update)
âœ“ Focus on acceptance criteria (not implementation)
âœ“ Use BDD (Given-When-Then stays stable)
âœ“ Regular grooming sessions

Challenge 3: Technical Debt in Test Automation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem: Automation flaky, maintenance burden

Solutions:
âœ“ Allocate time for test maintenance (20% of sprint)
âœ“ Review test code (same standards as product code)
âœ“ Remove obsolete tests
âœ“ Refactor duplicated test code
âœ“ Use page object model (maintainable structure)

Challenge 4: Limited QA Resources
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem: 1 QA for 5 developers

Solutions:
âœ“ Whole team testing (developers test too)
âœ“ Automate repetitive tests
âœ“ Pair testing (QA + Dev)
âœ“ Developers write unit tests (mandatory)
âœ“ Focus QA on exploratory, usability, edge cases

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

### 5.2 DevOps and CI/CD Testing

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
DEVOPS & CI/CD TESTING BEST PRACTICES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DEVOPS CULTURE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DevOps = Development + Operations (+ QA)

Traditional Model (Silos):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dev    â”‚ â†’  â”‚    QA    â”‚ â†’  â”‚   Ops    â”‚
â”‚ (builds) â”‚    â”‚ (tests)  â”‚    â”‚ (deploys)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Problems: Handoffs, delays, blame culture

DevOps Model (Collaboration):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Dev + QA + Ops (One Team)            â”‚
â”‚   Build â†’ Test â†’ Deploy (Automated)       â”‚
â”‚   Shared Responsibility & Ownership       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Benefits: Fast feedback, automation, collaboration

Key Principles:
1. Automation (CI/CD pipelines)
2. Continuous Testing
3. Shift Left on Security
4. Infrastructure as Code
5. Monitoring and Feedback

CONTINUOUS INTEGRATION (CI):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Definition: Automatically build and test code every commit

CI Pipeline:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Code Commit (Developer pushes to Git)
   â†“
2. CI Server Triggered (Jenkins, GitHub Actions, GitLab CI)
   â†“
3. Build Application
   - Compile code
   - Resolve dependencies
   - Create artifacts
   â†“
4. Run Unit Tests
   - Execute all unit tests
   - Code coverage check (>80%)
   - Fail build if tests fail
   â†“
5. Static Code Analysis
   - SonarQube: Code quality, bugs, vulnerabilities
   - ESLint/Pylint: Code standards
   - Security scanning
   â†“
6. Build Docker Image (if applicable)
   â†“
7. Publish Artifacts
   - Store in artifact repository
   - Version tagging
   â†“
8. Notify Team
   - Success: Green build âœ…
   - Failure: Alert developers ğŸš¨

Example CI Configuration (GitHub Actions):
```yaml
name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    
    - name: Set up Node.js
      uses: actions/setup-node@v2
      with:
        node-version: '16'
    
    - name: Install dependencies
      run: npm install
    
    - name: Run linter
      run: npm run lint
    
    - name: Run unit tests
      run: npm test
    
    - name: Check code coverage
      run: npm run coverage
      # Fail if coverage < 80%
    
    - name: Build application
      run: npm run build
    
    - name: Run integration tests
      run: npm run test:integration
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v2
      with:
        name: build
        path: dist/
    
    - name: Notify team
      if: failure()
      uses: slack-notify@v1
      with:
        webhook: ${{ secrets.SLACK_WEBHOOK }}
        message: "Build failed on ${{ github.ref }}"
```

Benefits of CI:
âœ“ Early bug detection (within minutes of commit)
âœ“ Reduced integration issues
âœ“ Faster feedback loop
âœ“ Always in releasable state
âœ“ Improved code quality

CONTINUOUS TESTING IN CI/CD:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Test Pyramid in CI/CD:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Layer 1: Unit Tests (Run Every Commit)
- Speed: Seconds
- Frequency: Every commit
- Coverage: 60% of tests
- Tool: Jest, pytest, JUnit
- Example: 2000 unit tests in 30 seconds

Layer 2: Integration Tests (Run Every Commit)
- Speed: Minutes
- Frequency: Every commit
- Coverage: 30% of tests
- Tool: TestNG, REST Assured, Postman
- Example: 300 API tests in 5 minutes

Layer 3: UI Tests (Run on Merge to Main)
- Speed: 30-60 minutes
- Frequency: Main branch merges, nightly
- Coverage: 10% of tests
- Tool: Selenium, Cypress, Playwright
- Example: 100 UI tests in 45 minutes

Test Strategy by Stage:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

STAGE 1: Commit Stage (Every Commit)
Tests: Unit tests, static analysis
Time: < 10 minutes
Goal: Fast feedback on code quality

STAGE 2: Acceptance Stage (After Commit Stage)
Tests: Integration tests, API tests, smoke tests
Time: 20-30 minutes
Goal: Validate functional behavior

STAGE 3: UAT Stage (After Acceptance)
Tests: Full regression, E2E tests, UI tests
Time: 1-2 hours
Goal: Comprehensive validation

STAGE 4: Production Stage (After UAT)
Tests: Smoke tests, monitoring
Time: 5-10 minutes
Goal: Verify production deployment

CONTINUOUS DEPLOYMENT (CD):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Definition: Automatically deploy to production after passing tests

CD Pipeline:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Code Commit
   â†“
2. CI Pipeline (Build + Test)
   â†“
3. Deploy to Dev Environment
   - Automated deployment
   - Smoke tests
   â†“
4. Deploy to QA Environment
   - Automated deployment
   - Full regression suite
   - Performance tests
   â†“
5. Deploy to Staging (Pre-Production)
   - Automated deployment
   - UAT
   - Security scans
   â†“
6. Deploy to Production
   - Automated deployment (with approval gate)
   - Blue-Green deployment or Canary release
   - Smoke tests in production
   - Monitor metrics
   â†“
7. Rollback if Issues Detected
   - Automated rollback
   - Alert team

Deployment Strategies:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Blue-Green Deployment:
   - Blue: Current production version
   - Green: New version deployed in parallel
   - Switch traffic from Blue to Green
   - If issues: Switch back to Blue (instant rollback)
   
   Benefits: Zero downtime, instant rollback

2. Canary Release:
   - Deploy new version to small % of users (5%)
   - Monitor metrics (errors, performance)
   - If good: Gradually increase to 100%
   - If issues: Rollback
   
   Benefits: Risk mitigation, real user feedback

3. Rolling Deployment:
   - Deploy to servers one by one
   - Monitor each server
   - Continue if healthy
   
   Benefits: No downtime, gradual rollout

TESTING IN PRODUCTION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Why Test in Production?
- Test environment never 100% matches production
- Real user behavior unpredictable
- Scale and load different
- Third-party integrations behave differently

Techniques:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Smoke Tests After Deployment:
   - Verify critical paths work
   - Run immediately after deploy
   - Example: Login, checkout, payment

2. Synthetic Monitoring:
   - Automated scripts simulate user actions
   - Run continuously (every 5 minutes)
   - Alert if failures detected

3. Feature Flags:
   - Deploy code, but keep feature disabled
   - Enable for internal users first
   - Gradually enable for all users
   - Disable instantly if issues

4. A/B Testing:
   - 50% users see old version
   - 50% users see new version
   - Compare metrics
   - Choose winner

5. Chaos Engineering:
   - Intentionally break things to test resilience
   - Simulate server failures, network issues
   - Verify system recovers
   - Example: Netflix Chaos Monkey

Example Monitoring Dashboard:
```
PRODUCTION HEALTH DASHBOARD

Response Time: 250ms (Target: <500ms) âœ…
Error Rate: 0.5% (Target: <1%) âœ…
Uptime: 99.95% (Target: 99.9%) âœ…
Throughput: 5000 req/min âœ…

Recent Deployments:
- v2.3.4: Deployed 2 hours ago âœ…
  * Smoke tests: Passed
  * Error rate: 0.5% (unchanged)
  * Response time: 250ms (improved from 300ms)

Alerts:
ğŸŸ¢ No active alerts
```

TEST AUTOMATION IN CI/CD:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Best Practices:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. FAST FEEDBACK:
   âœ“ Unit tests: < 10 minutes
   âœ“ Integration tests: < 30 minutes
   âœ“ UI tests: < 1 hour
   
   If tests too slow: Developers skip them

2. RELIABLE TESTS:
   âœ“ No flaky tests (random failures)
   âœ“ Deterministic (same input = same output)
   âœ“ Independent (tests don't depend on each other)
   âœ“ Repeatable
   
   If tests flaky: Lose trust, ignore failures

3. MAINTAINABLE TESTS:
   âœ“ Page Object Model (UI tests)
   âœ“ DRY principle (Don't Repeat Yourself)
   âœ“ Clear test names
   âœ“ Good error messages
   
   If hard to maintain: Test debt accumulates

4. RIGHT LEVEL OF TESTING:
   âœ“ Unit tests: Business logic
   âœ“ Integration tests: API contracts, database
   âœ“ UI tests: Critical user journeys only
   
   Don't test everything at UI level (slow, brittle)

5. TEST DATA MANAGEMENT:
   âœ“ Each test creates own data
   âœ“ Clean up after test
   âœ“ Use test database (not production)
   âœ“ Seed data for tests
   
   Bad: Shared test data = race conditions

Example Test Organization:
```
tests/
â”œâ”€â”€ unit/               # Fast, run every commit
â”‚   â”œâ”€â”€ auth.test.js
â”‚   â”œâ”€â”€ payment.test.js
â”‚   â””â”€â”€ cart.test.js
â”œâ”€â”€ integration/        # Medium speed, run every commit
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ user-api.test.js
â”‚   â”‚   â””â”€â”€ order-api.test.js
â”‚   â””â”€â”€ database/
â”‚       â””â”€â”€ migrations.test.js
â””â”€â”€ e2e/               # Slow, run on merge/nightly
    â”œâ”€â”€ critical/       # Must pass for deploy
    â”‚   â”œâ”€â”€ login.spec.js
    â”‚   â””â”€â”€ checkout.spec.js
    â””â”€â”€ extended/       # Nice to have
        â”œâ”€â”€ profile.spec.js
        â””â”€â”€ search.spec.js
```

SHIFT LEFT ON SECURITY (DevSecOps):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Security in CI/CD Pipeline:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Stage 1: Code Commit
- Git pre-commit hooks: Check for secrets
- IDE plugins: Security linting

Stage 2: Build
- Dependency scanning (Snyk, Dependabot)
- Check for vulnerable libraries
- Fail build if critical vulnerabilities

Stage 3: Static Analysis
- SAST (Static Application Security Testing)
- SonarQube: Security hotspots
- Find SQL injection, XSS vulnerabilities

Stage 4: Deploy to Test Environment
- DAST (Dynamic Application Security Testing)
- OWASP ZAP: Scan running application
- Penetration testing (automated)

Stage 5: Production
- Runtime security monitoring
- WAF (Web Application Firewall)
- SIEM (Security Information and Event Management)

Example Security Check (CI Pipeline):
```yaml
- name: Check for secrets
  run: |
    # Fail if secrets (API keys, passwords) in code
    trufflehog git file://. --fail

- name: Scan dependencies
  run: |
    npm audit --audit-level=high
    # Fail if high/critical vulnerabilities

- name: SAST scan
  run: |
    sonarqube-scanner
    # Fail if security hotspots

- name: Container scan
  run: |
    trivy image myapp:latest
    # Scan Docker image for vulnerabilities
```

METRICS FOR CI/CD:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Key Metrics:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Build Success Rate:
   Formula: (Successful Builds / Total Builds) Ã— 100
   Target: >90%
   
   Example: 180 passed / 200 total = 90%

2. Build Duration:
   Unit tests: <10 minutes
   Full pipeline: <1 hour
   
   Track trend: Are builds getting slower?

3. Deployment Frequency:
   How often deploying to production?
   High performers: Multiple times per day
   Medium: Weekly
   Low: Monthly

4. Lead Time for Changes:
   Time from code commit to production
   Target: <1 day

5. Mean Time to Recovery (MTTR):
   Time to fix production issue
   Target: <1 hour

6. Change Failure Rate:
   % of deployments causing production issues
   Target: <15%

Example Metrics Dashboard:
```
CI/CD METRICS - January 2026

Build Success Rate: 92% âœ… (Target: >90%)
Avg Build Duration: 45 min âœ… (Target: <1 hour)
Deployment Frequency: 3x per day âœ…
Lead Time: 4 hours âœ… (Target: <1 day)
MTTR: 30 min âœ… (Target: <1 hour)
Change Failure Rate: 12% âœ… (Target: <15%)

Trend: â†—ï¸ Improving
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Industry-Specific Testing

### 6.1 Testing by Industry Domain

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
INDUSTRY-SPECIFIC TESTING CONSIDERATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. HEALTHCARE / MEDICAL DEVICES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Regulatory Requirements:
- FDA 21 CFR Part 11 (Electronic Records)
- HIPAA (Patient Data Privacy)
- HL7 Standards (Health Information Exchange)
- IEC 62304 (Medical Device Software)

Critical Focus Areas:
âœ“ Patient Safety (highest priority)
âœ“ Data Privacy and Security
âœ“ Audit Trails (who, what, when)
âœ“ Data Integrity
âœ“ Interoperability (different systems)

Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Validation vs Verification:
- Verification: Building product right (meets specs)
- Validation: Building right product (meets user needs)
- Both required for FDA approval

Risk Classification (FDA):
Class I: Low risk (tongue depressors)
Class II: Moderate risk (blood pressure monitors)
Class III: High risk (pacemakers, insulin pumps)

Higher class = More rigorous testing

Test Documentation:
âœ“ Test Plan (detailed, approved)
âœ“ Test Cases (traceable to requirements)
âœ“ Test Execution Records (signed, dated)
âœ“ Validation Report (summary)
âœ“ Traceability Matrix (requirement â†’ test)

Example Test Scenarios:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Medical Records System:
- Patient data encrypted at rest and in transit
- Access control: Only authorized personnel
- Audit log: Every data access recorded
- Data integrity: Checksums, no tampering
- Privacy: PHI (Protected Health Information) protected
- Backup & Recovery: Data recoverable

Example Test Case:
```
TC-HIPAA-001: Verify unauthorized access denied

Preconditions:
- User "John Nurse" logged in
- Patient "Jane Doe" record exists
- John not assigned to Jane's care

Steps:
1. John attempts to access Jane's medical record
2. System checks authorization

Expected Result:
âœ— Access DENIED
âœ“ Error message: "You are not authorized to access this record"
âœ“ Audit log entry: "Unauthorized access attempt by John Nurse"
âœ“ Security team notified

Pass Criteria: Access denied, audit logged
```

Tools:
- HL7 Inspector (message validation)
- DICOM Viewer (medical imaging)
- Performance testing (life-critical response times)

2. FINANCIAL SERVICES / BANKING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Regulatory Requirements:
- PCI DSS (Payment Card Industry Data Security Standard)
- SOX (Sarbanes-Oxley Act)
- GDPR (Europe), CCPA (California)
- Basel III (Banking regulations)

Critical Focus Areas:
âœ“ Transaction Accuracy (penny matters)
âœ“ Security (fraud prevention)
âœ“ Compliance (audit trails)
âœ“ Performance (high transaction volume)
âœ“ Disaster Recovery (zero data loss)

Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Functional Testing:
- Transactions: Debits, credits, transfers
- Interest calculations (to the penny)
- Currency conversions
- Account balance updates
- Reconciliation

Security Testing:
- Penetration testing (mandatory)
- Vulnerability scanning (quarterly)
- Session management
- Encryption (in transit, at rest)
- Two-factor authentication

Performance Testing:
- Load: 10,000 concurrent users
- Stress: Peak loads (month-end, tax season)
- Scalability: Can handle growth?

Example Test Scenarios:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Banking Transfer:
```
TC-BANK-001: Verify fund transfer accuracy

Preconditions:
- Account A balance: $1000.00
- Account B balance: $500.00
- Transfer amount: $250.00

Steps:
1. User initiates transfer from A to B ($250)
2. System validates: Sufficient balance in A
3. System debits A: $250
4. System credits B: $250
5. System logs transaction

Expected Results:
âœ“ Account A balance: $750.00 (exactly)
âœ“ Account B balance: $750.00 (exactly)
âœ“ Transaction logged with timestamp
âœ“ Confirmation sent to user
âœ“ Audit trail created

Negative Tests:
âœ— Transfer $2000 (insufficient funds) â†’ DENIED
âœ— Transfer $-100 (negative amount) â†’ DENIED
âœ— Transfer to closed account â†’ DENIED

Data Validation:
- Amounts: Max 2 decimal places
- No rounding errors
- Atomic transaction (all or nothing)
```

Compliance Testing:
- PCI DSS Scan (quarterly)
- SOX Controls Testing (annual)
- Data Retention Policy (7 years)
- Right to be Forgotten (GDPR)

3. E-COMMERCE / RETAIL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Critical Focus Areas:
âœ“ User Experience (conversion rate)
âœ“ Performance (page load speed)
âœ“ Payment Processing (PCI DSS)
âœ“ Search & Recommendations
âœ“ Mobile Experience
âœ“ Checkout Flow (low abandonment)

Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Functional Testing:
- Product catalog (search, filter, sort)
- Shopping cart (add, remove, update)
- Checkout (guest checkout, saved addresses)
- Payment (credit card, PayPal, Apple Pay)
- Order tracking
- Returns & refunds

Usability Testing:
- First-time buyer: Can complete purchase in <5 min?
- Mobile: Thumb-friendly buttons
- Accessibility: Screen reader compatible
- Clarity: Clear product descriptions, images

Performance Testing:
- Page load: <3 seconds (or lose customers)
- Peak load: Black Friday, Cyber Monday
- Scalability: 10x normal traffic
- CDN: Images load fast globally

Example Test Scenarios:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Checkout Flow:
```
TC-ECOM-001: Complete purchase flow

Steps:
1. Browse products
2. Add 3 items to cart
3. Apply discount code (10% off)
4. Proceed to checkout
5. Enter shipping address
6. Select shipping method
7. Enter payment (credit card)
8. Review order
9. Place order

Expected Results:
âœ“ Order total calculated correctly
âœ“ Discount applied: 10% off
âœ“ Shipping cost added
âœ“ Tax calculated based on address
âœ“ Payment processed (Stripe)
âœ“ Order confirmation page displayed
âœ“ Confirmation email sent
âœ“ Inventory updated (items reserved)
âœ“ Order appears in "My Orders"

Performance:
âœ“ Each step loads in <2 seconds
âœ“ Payment processing <5 seconds

Negative Tests:
âœ— Invalid credit card â†’ Error message, retry
âœ— Expired card â†’ Declined, alternative payment
âœ— Out of stock item â†’ Removed from cart, notified
```

A/B Testing:
- Test two checkout designs
- Measure conversion rate
- Choose winner

4. AUTOMOTIVE / EMBEDDED SYSTEMS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Standards:
- ISO 26262 (Automotive Functional Safety)
- AUTOSAR (Automotive Software Architecture)
- MISRA C (Coding Guidelines)

Critical Focus Areas:
âœ“ Safety (ASIL levels A-D)
âœ“ Real-time Performance
âœ“ Reliability (operate in harsh conditions)
âœ“ Hardware Integration
âœ“ Fault Tolerance

Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Safety Testing:
- ASIL D: Highest safety (airbags, brakes)
- Fault injection testing
- Fail-safe behavior
- Redundancy testing

Hardware-in-Loop (HIL) Testing:
- Simulate sensors and actuators
- Test ECU (Electronic Control Unit) behavior
- Real-time constraints

Environmental Testing:
- Temperature: -40Â°C to +85Â°C
- Vibration, shock
- Electromagnetic interference

Example Test Scenarios:
```
TC-AUTO-001: Anti-lock Braking System (ABS)

Scenario: Emergency braking on wet road

Inputs:
- Wheel speed sensors: Detecting wheel lock
- Brake pedal: 100% pressure
- Road condition: Wet

Expected Behavior:
âœ“ ABS activates within 10ms
âœ“ Brake pressure modulated (pulsing)
âœ“ Wheels do not lock
âœ“ Vehicle maintains steering control
âœ“ Stopping distance minimized

Safety Requirement: ASIL D (critical)
```

5. TELECOMMUNICATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Critical Focus Areas:
âœ“ Network Performance (latency, throughput)
âœ“ Reliability (99.999% uptime = 5 min/year downtime)
âœ“ Scalability (millions of users)
âœ“ Protocol Compliance (3GPP, LTE, 5G)
âœ“ Interoperability (different vendors)

Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Performance Testing:
- Call setup time: <3 seconds
- Latency: <50ms (voice), <100ms (data)
- Throughput: Gbps (5G)
- Packet loss: <0.1%

Load Testing:
- Simulate 1 million concurrent calls
- Network congestion scenarios
- Failover testing

Protocol Testing:
- SIP, RTP, RTCP (VoIP protocols)
- Packet capture and analysis
- Conformance testing

Example:
```
TC-TELECOM-001: Voice call quality

Test Setup:
- 10,000 simultaneous calls
- Mix: 60% voice, 40% data

Measurements:
- Call success rate: >99.5%
- Voice quality (MOS): >4.0 (out of 5)
- Latency: <150ms
- Jitter: <30ms
- Packet loss: <1%

Pass Criteria: All thresholds met
```

6. GAMING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Critical Focus Areas:
âœ“ Performance (60 FPS smooth)
âœ“ User Experience (fun, engaging)
âœ“ Multiplayer (lag, cheating)
âœ“ Cross-platform (PC, console, mobile)
âœ“ Monetization (in-app purchases)

Testing Approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Functional Testing:
- Game mechanics (jumping, shooting)
- Progression (levels, achievements)
- Save/Load game
- Multiplayer matchmaking

Performance Testing:
- FPS: Maintain 60 FPS
- Load times: <5 seconds
- Memory usage: Within limits
- Battery drain (mobile)

Compatibility Testing:
- Different devices (iPhone, Android, PC)
- Different screen resolutions
- Different graphics settings

Playtesting:
- Beta testers play game
- Gather feedback
- Balance difficulty
- Find exploits/cheats

Example:
```
TC-GAME-001: Multiplayer lag test

Test Setup:
- 100 players in same match
- Simulate network conditions

Scenarios:
1. Low latency (10ms): Smooth gameplay
2. Medium latency (100ms): Acceptable
3. High latency (300ms): Laggy but playable
4. Very high (500ms): Unplayable

Measurements:
- Server tick rate: 60 Hz
- Client-server sync: <100ms
- Hit detection accuracy: >95%

Pass: Playable up to 300ms latency
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
COMPLIANCE & CERTIFICATION CHECKLIST
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Healthcare:
â–¡ FDA 21 CFR Part 11 compliance
â–¡ HIPAA compliance (if patient data)
â–¡ IEC 62304 (medical device software)
â–¡ Risk management (ISO 14971)
â–¡ Usability engineering (IEC 62366)

Financial:
â–¡ PCI DSS compliance (if processing payments)
â–¡ SOX compliance (public companies)
â–¡ GDPR / CCPA (data privacy)
â–¡ Penetration testing (annual)
â–¡ Security audit (quarterly)

General:
â–¡ ISO 29119 (software testing)
â–¡ ISO 25010 (software quality)
â–¡ WCAG 2.1 AA (accessibility)
â–¡ OWASP Top 10 (security)
â–¡ GDPR (if EU users)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Practical Exercises

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PRACTICAL EXERCISES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXERCISE 1: Create ISO 29119 Compliant Test Plan
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scenario: You are the QA Lead for an e-commerce mobile app project
(iOS and Android). The sprint will add a "Buy Now" one-click checkout
feature.

Task: Create a comprehensive Test Plan following ISO 29119-3 template
with the following mandatory sections:

1. Test Plan Identifier
2. Introduction (project context, scope)
3. Test Items (what will be tested)
4. Features to be Tested
5. Features NOT to be Tested
6. Test Approach (levels, types, techniques)
7. Pass/Fail Criteria (specific metrics)
8. Suspension & Resumption Criteria
9. Test Deliverables (documents, reports)
10. Test Environment (devices, OS versions, tools)
11. Responsibilities (who does what)
12. Staffing & Training Needs
13. Schedule (timeline with milestones)
14. Risks & Contingencies
15. Approvals (sign-off section)

Additional Requirements:
- Reference specific ISO 29119 test techniques to be used
- Include risk-based test prioritization
- Define entry/exit criteria for each test level
- Specify automation strategy (Test Pyramid approach)
- Include non-functional testing (performance, security, usability)

Deliverable: Complete test plan document (4-6 pages)

EXERCISE 2: ISO 25010 Quality Characteristics Matrix
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scenario: You are defining quality requirements for an online banking
application.

Task: Create a Quality Requirements Matrix using ISO 25010's 8 quality
characteristics. For each characteristic:

1. Functional Suitability
2. Performance Efficiency
3. Compatibility
4. Usability
5. Reliability
6. Security
7. Maintainability
8. Portability

For EACH characteristic, define:
- Specific requirement (measurable)
- Test approach/technique
- Acceptance criteria (pass/fail threshold)
- Priority (Critical/High/Medium/Low)
- Test tools needed

Example Template:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Quality      â”‚ Requirement     â”‚ Test Approachâ”‚ Criteria  â”‚Priority â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Performance  â”‚ Page load <2sec â”‚ JMeter load  â”‚ 95th %ile â”‚Critical â”‚
â”‚              â”‚                 â”‚ test         â”‚ <2s       â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Deliverable: Complete quality requirements matrix for all 8 characteristics
with at least 2 sub-characteristics per main characteristic (16 total requirements)

EXERCISE 3: ISTQB Foundation Sample Exam
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Task: Create a 20-question sample ISTQB Foundation Level exam covering:
- Chapter 1: Fundamentals (4 questions)
- Chapter 2: Testing Throughout SDLC (3 questions)
- Chapter 3: Static Testing (3 questions)
- Chapter 4: Test Techniques (5 questions)
- Chapter 5: Test Management (3 questions)
- Chapter 6: Tool Support (2 questions)

Requirements:
- Multiple choice (4 options each)
- Mix of knowledge levels (remember, understand, apply)
- Include realistic scenarios
- Provide correct answers with explanations
- Reference ISTQB syllabus sections

Example Question Format:
```
Q1. Which of the following is NOT one of the seven testing principles?
a) Early testing
b) Exhaustive testing is possible
c) Defect clustering
d) Testing is context dependent

Answer: b)
Explanation: The principle states "Exhaustive testing is IMPOSSIBLE,"
not possible. Testing all combinations is not feasible.
Syllabus Reference: 1.3 Seven Testing Principles
```

Deliverable: 20 questions with answers and explanations

EXERCISE 4: TMMi Assessment & Improvement Plan
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scenario: You are hired as QA Manager for a mid-size software company
(50 developers, 10 testers). Current test maturity is ad-hoc (Level 1).

Task: Conduct a TMMi assessment and create an improvement roadmap.

Part A: Current State Assessment
For each TMMi Level 2 process area, rate the current state:
1. Test Policy and Strategy - [Rating: Not/Partially/Largely/Fully Achieved]
2. Test Planning - [Rating]
3. Test Monitoring and Control - [Rating]
4. Test Design and Execution - [Rating]

Provide evidence for each rating (what you observed).

Part B: Gap Analysis
Identify gaps between current state (Level 1) and target state (Level 2).
List specific deficiencies.

Part C: Improvement Plan (12-month roadmap)
Create quarterly plan with specific, actionable items:

Quarter 1 (Months 1-3):
- Actions: [List specific initiatives]
- Deliverables: [Expected outputs]
- Resources needed: [Budget, people, tools]
- Success metrics: [How to measure]

Quarter 2-4: [Similar breakdown]

Part D: Expected Outcomes
Quantify expected benefits:
- Defect reduction: X%
- Time to market: -Y days
- Test coverage: +Z%
- ROI: Calculate

Deliverable: TMMi assessment report + 12-month improvement plan (4-5 pages)

EXERCISE 5: Agile Testing Strategy Document
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scenario: Your team is transitioning from Waterfall to Agile (Scrum).
Sprint duration: 2 weeks. Team: 5 developers, 2 QA, 1 PO, 1 SM.

Task: Create an Agile Testing Strategy document that addresses:

1. Testing Approach:
   - Whole team quality ownership
   - Shift-left testing
   - Test automation pyramid
   - Continuous testing in CI/CD

2. Testing in Sprint:
   - Day-by-day testing activities (10-day sprint)
   - QA involvement in each Scrum ceremony
   - Definition of Done (DoD) with testing criteria

3. Agile Testing Quadrants:
   - Which quadrants apply to your project?
   - Who is responsible for each quadrant?
   - Automation strategy per quadrant

4. Test Types & Levels:
   - Unit tests (by developers)
   - Integration tests (API testing)
   - UI tests (critical paths only)
   - Exploratory testing (sessions)

5. Test Automation:
   - What to automate vs manual
   - Tools selection (justify choices)
   - Test pyramid ratios (60% unit, 30% integration, 10% UI)
   - CI/CD integration

6. Metrics:
   - Sprint testing metrics (daily, sprint-end)
   - Velocity, quality trends
   - Defect trends

7. Challenges & Mitigation:
   - Short iterations
   - Changing requirements
   - Test automation maintenance
   - Resource constraints

Deliverable: Agile Testing Strategy (5-6 pages)

EXERCISE 6: Industry Compliance Checklist
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Task: Choose ONE industry domain and create a comprehensive compliance
testing checklist:

Options:
A) Healthcare (HIPAA, FDA 21 CFR Part 11)
B) Financial (PCI DSS, SOX)
C) E-commerce (PCI DSS, GDPR, CCPA)

For your chosen industry, create:

1. Regulatory Requirements List:
   - List all applicable regulations/standards
   - Briefly explain each requirement
   - Identify which apply to your specific project

2. Compliance Testing Checklist:
   Create detailed checklist with:
   - Compliance area (e.g., Data Encryption)
   - Specific requirement (e.g., "All PII encrypted at rest")
   - Test case ID
   - Test description
   - Expected evidence
   - Pass/Fail criteria
   - Status (Tested/Not Tested/N/A)

3. Test Scenarios:
   Write 10 detailed test cases covering critical compliance areas.
   Use proper test case format:
   - Preconditions
   - Steps
   - Expected results
   - Compliance reference

4. Audit Readiness:
   - Documentation requirements
   - Evidence to collect
   - Audit preparation checklist

Example (Healthcare - HIPAA):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Compliance Area â”‚ Requirement                          â”‚ Status   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Access Control  â”‚ Unique user IDs for all users       â”‚ âœ… Testedâ”‚
â”‚                 â”‚ Test: TC-HIPAA-001                   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Encryption      â”‚ PHI encrypted at rest (AES-256)     â”‚ âœ… Testedâ”‚
â”‚                 â”‚ Test: TC-HIPAA-010                   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Audit Logs      â”‚ All PHI access logged with timestamp â”‚ Pending  â”‚
â”‚                 â”‚ Test: TC-HIPAA-020                   â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Deliverable: Industry-specific compliance testing package (6-8 pages)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Assessment Questions

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ASSESSMENT QUESTIONS (25 Total)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SECTION A: Multiple Choice (15 Questions)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q1. ISO/IEC 29119 consists of how many parts?
a) 3 parts
b) 4 parts
c) 5 parts
d) 6 parts

Answer: c) 5 parts
Explanation: ISO 29119 has 5 parts: Concepts & Definitions, Test Processes,
Test Documentation, Test Techniques, and Keyword-Driven Testing.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q2. According to ISO 25010, which is NOT one of the 8 product quality
characteristics?
a) Functional Suitability
b) Testability
c) Security
d) Portability

Answer: b) Testability
Explanation: Testability is a sub-characteristic of Maintainability, not
a main characteristic. The 8 main characteristics are: Functional Suitability,
Performance Efficiency, Compatibility, Usability, Reliability, Security,
Maintainability, and Portability.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q3. ISTQB Foundation Level exam has how many questions and what is the
passing score?
a) 40 questions, 65% pass
b) 40 questions, 70% pass
c) 50 questions, 65% pass
d) 50 questions, 70% pass

Answer: a) 40 questions, 65% pass
Explanation: ISTQB Foundation requires 26 out of 40 questions correct (65%)
to pass. The exam is 60 minutes duration.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q4. Which testing principle states that testing cannot prove the absence
of defects?
a) Early testing
b) Testing shows presence of defects, not absence
c) Exhaustive testing is impossible
d) Defect clustering

Answer: b) Testing shows presence of defects, not absence
Explanation: This is the first of the seven testing principles. Testing
can prove defects exist but cannot prove they don't exist.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q5. In TMMi, at which maturity level is "Test Organization" introduced
as a process area?
a) Level 1 (Initial)
b) Level 2 (Managed)
c) Level 3 (Defined)
d) Level 4 (Measured)

Answer: c) Level 3 (Defined)
Explanation: Test Organization is one of the process areas introduced at
TMMi Level 3, along with Test Training Program and Test Lifecycle Integration.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q6. Which test design technique is classified as specification-based
(black-box) in ISO 29119-4?
a) Statement coverage
b) Decision coverage
c) Boundary value analysis
d) Path coverage

Answer: c) Boundary value analysis
Explanation: BVA is a black-box technique. Statement, decision, and path
coverage are white-box (structure-based) techniques.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q7. In the Agile Testing Quadrants, which quadrant contains unit tests?
a) Q1 (Technology-facing, Supporting Team)
b) Q2 (Business-facing, Supporting Team)
c) Q3 (Business-facing, Critique Product)
d) Q4 (Technology-facing, Critique Product)

Answer: a) Q1 (Technology-facing, Supporting Team)
Explanation: Q1 contains unit tests, component tests, and API tests that
guide development and are technology-facing.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q8. What percentage of tests should be at the unit test level in the
Test Automation Pyramid?
a) 10%
b) 30%
c) 60%
d) 100%

Answer: c) 60%
Explanation: The Test Pyramid recommends 60% unit tests, 30% integration/
API tests, and 10% UI/E2E tests.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q9. Which regulatory standard is required for medical device software?
a) PCI DSS
b) IEC 62304
c) SOX
d) Basel III

Answer: b) IEC 62304
Explanation: IEC 62304 is the international standard for medical device
software lifecycle processes. PCI DSS is for payment cards, SOX for
financial reporting, Basel III for banking.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q10. In CI/CD, what is the recommended maximum time for unit tests to run?
a) 1 minute
b) 10 minutes
c) 30 minutes
d) 1 hour

Answer: b) 10 minutes
Explanation: Unit tests should run in under 10 minutes to provide fast
feedback to developers. If longer, developers skip running them.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q11. What does "shift left" mean in testing?
a) Move testing team to different building
b) Test only on left side of application
c) Move testing activities earlier in SDLC
d) Reduce testing time

Answer: c) Move testing activities earlier in SDLC
Explanation: Shift left means performing testing activities earlier in the
development lifecycle to catch defects sooner when they're cheaper to fix.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q12. Which deployment strategy allows instant rollback by switching
traffic between two identical environments?
a) Rolling deployment
b) Canary release
c) Blue-Green deployment
d) Big bang deployment

Answer: c) Blue-Green deployment
Explanation: Blue-Green maintains two identical environments (blue=old,
green=new). Traffic switches from blue to green, allowing instant rollback
by switching back to blue.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q13. In financial services, what does PCI DSS stand for?
a) Payment Card Industry Data Security Standard
b) Personal Credit Information Data Storage Standard
c) Payment Compliance and Insurance Data Standard
d) Protected Card Identification Security System

Answer: a) Payment Card Industry Data Security Standard
Explanation: PCI DSS is the security standard for organizations that handle
credit card information, including requirements for testing and compliance.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q14. TPI NEXT is an alternative to which process improvement model?
a) CMMI
b) TMMi
c) Six Sigma
d) ISO 9001

Answer: b) TMMi
Explanation: TPI NEXT (Test Process Improvement) is an alternative test
maturity model to TMMi, focusing on business-driven improvement.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q15. Which of the following is a DevOps metric?
a) Test case count
b) Deployment frequency
c) Bug severity
d) Test coverage

Answer: b) Deployment frequency
Explanation: Deployment frequency (how often deploying to production) is
a key DevOps metric. Other DevOps metrics include lead time, MTTR, and
change failure rate.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SECTION B: True/False (5 Questions)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q16. ISO 29119 Part 5 covers Keyword-Driven Testing.

Answer: TRUE
Explanation: ISO 29119-5 standardizes the keyword-driven test approach,
where test cases are written using keywords (actions) separated from test
data.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q17. ISTQB Foundation Level certification requires 2 years of testing
experience as a prerequisite.

Answer: FALSE
Explanation: ISTQB Foundation Level has NO prerequisites. Anyone can take
the exam without prior experience or training requirements.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q18. In Agile Testing Quadrants, Q3 (exploratory testing, UAT) is 100%
automated.

Answer: FALSE
Explanation: Q3 tests (exploratory, usability, UAT) are primarily manual
and only 10-20% can be automated. These require human creativity and
judgment.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q19. TMMi Level 5 (Optimizing) includes Defect Prevention as a process area.

Answer: TRUE
Explanation: Level 5 introduces three process areas: Defect Prevention,
Quality Control, and Test Process Optimization, focusing on continuous
improvement.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q20. Testing in production is always a bad practice and should be avoided.

Answer: FALSE
Explanation: Testing in production is a valid practice when done correctly
(smoke tests, synthetic monitoring, canary releases, A/B testing). Production
environments differ from test environments and require validation.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SECTION C: Scenario-Based Questions (5 Questions)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q21. Your healthcare application must comply with HIPAA. During testing,
you discover that patient data is transmitted over HTTP (unencrypted).
What should you do?

Answer:
This is a CRITICAL security and compliance issue that must be addressed
immediately:

Actions:
1. Log as Critical Bug:
   - Reference: HIPAA Security Rule (Â§164.312(e)(1))
   - Risk: PHI (Protected Health Information) exposure
   - Compliance violation: Could result in fines up to $1.5M

2. Immediate Escalation:
   - Alert development team immediately
   - Notify security officer
   - Inform management of compliance risk

3. Testing Recommendation:
   - BLOCK release until fixed
   - All data transmission must use HTTPS (TLS 1.2+)
   - Verify fix with:
     * Network traffic capture (Wireshark)
     * SSL/TLS verification
     * Penetration testing

4. Audit Trail:
   - Document finding with evidence
   - Document remediation steps
   - Prepare for compliance audit

5. Prevention:
   - Add to security checklist
   - Include in CI/CD pipeline (automated TLS check)
   - Security training for dev team

This is not just a bugâ€”it's a compliance violation with legal consequences.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q22. You're implementing CI/CD for the first time. Your full regression
suite takes 8 hours to run, causing delays. How do you optimize this for
CI/CD?

Answer:
Comprehensive optimization strategy:

Phase 1: Immediate Actions (Week 1)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Test Parallelization:
   - Run tests in parallel (use CI tools' parallel execution)
   - 8 hours â†’ 1-2 hours (with 8 parallel workers)

2. Test Categorization:
   - Critical: 100 tests (15 min)
   - High: 300 tests (1 hour)
   - Medium: 500 tests (3 hours)
   - Low: 600 tests (4 hours)

3. Staged Pipeline:
   Commit Stage: Critical tests only (15 min)
   Acceptance Stage: Critical + High (1.25 hours)
   Full Regression: All tests (nightly build)

Phase 2: Restructure Tests (Month 1)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

4. Test Pyramid Approach:
   Current: 80% UI tests (slow)
   Target: 60% unit, 30% API, 10% UI
   
   Actions:
   - Convert UI tests to API tests where possible
   - Developers write more unit tests
   - Keep UI tests for critical user journeys only

5. Remove Redundant Tests:
   - Analyze test coverage overlap
   - Remove duplicate tests
   - Archive obsolete tests
   - Target: Reduce by 30%

Phase 3: Optimize Performance (Month 2)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

6. Fix Slow Tests:
   - Profile test execution times
   - Optimize database setup/teardown
   - Use test data caching
   - Reduce unnecessary waits/sleeps

7. Infrastructure:
   - Upgrade CI server hardware
   - Use cloud-based CI (scalable)
   - Distributed test execution

Target Timeline:
- Week 1: 8 hours â†’ 2 hours (parallelization)
- Month 1: 2 hours â†’ 1 hour (restructure)
- Month 2: 1 hour â†’ 30 min (optimization)

Result: Fast feedback for developers, deployable anytime

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q23. Your organization wants to achieve TMMi Level 3 certification.
You're currently at Level 1. What's your 18-month roadmap?

Answer:
Strategic implementation plan:

Phase 1: Assessment & Foundation (Months 1-3)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Month 1: Current State Assessment
- Document existing test processes
- Interview stakeholders
- Identify gaps vs TMMi Level 2 & 3
- Get leadership buy-in

Month 2-3: Achieve Level 2 Foundation
Level 2 Process Areas (must achieve first):
âœ“ Test Policy and Strategy
âœ“ Test Planning
âœ“ Test Monitoring and Control
âœ“ Test Design and Execution

Actions:
- Write Organizational Test Policy
- Create test plan templates
- Implement test tracking (Jira/TestRail)
- Standardize test case format

Phase 2: Level 2 Implementation (Months 4-9)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Month 4-6: Process Rollout
- Train all teams on new processes
- Pilot with 2 projects
- Collect feedback and refine
- Tool implementation (test management)

Month 7-9: Level 2 Maturity
- All projects using standard processes
- Metrics collection started
- Regular process audits
- Document lessons learned

Interim Assessment: Verify Level 2 achieved

Phase 3: Level 3 Implementation (Months 10-15)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Month 10-12: Level 3 Process Areas
New processes to implement:
âœ“ Test Organization (dedicated QA team)
âœ“ Test Training Program
âœ“ Test Lifecycle and Integration
âœ“ Non-Functional Testing
âœ“ Peer Reviews

Actions:
- Establish QA organization structure
- Create training program (ISTQB for all)
- Integrate testing in all SDLC phases
- Formalize review processes
- Add performance/security testing

Month 13-15: Level 3 Maturity
- All processes operational
- Training completed
- Metrics show improvement
- Ready for assessment

Phase 4: Certification (Months 16-18)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Month 16: Pre-Assessment
- Internal audit
- Gap analysis
- Remediate findings

Month 17: Official Assessment
- TMMi assessor visit
- Evidence review
- Interviews
- Process observation

Month 18: Certification
- Address any findings
- Achieve TMMi Level 3 certification
- Celebrate and communicate success

Budget:
- Training: $50K
- Tools: $30K
- Consulting: $100K
- Assessment: $40K
Total: $220K

Expected ROI (Year 2):
- 25% defect reduction
- 20% faster releases
- 30% improved team productivity
- Customer satisfaction increase

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q24. You need to test a financial trading application where a bug could
cause millions in losses. Using ISO 25010, which quality characteristics
should be your TOP 3 priorities and why?

Answer:
Priority-ranked quality characteristics for financial trading:

PRIORITY 1: RELIABILITY (CRITICAL)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Why: System must operate correctly 24/7. Downtime = lost revenue.

Sub-characteristics to focus:
a) Maturity: System handles all scenarios without crashing
b) Availability: 99.99% uptime (52 min downtime/year max)
c) Fault Tolerance: Continues operating despite failures
d) Recoverability: Data recovery after crashes

Test Strategy:
- Soak testing (run for 48+ hours continuously)
- Failover testing (server crashes, network failures)
- Recovery testing (database corruption, power loss)
- Stress testing (extreme conditions)

Acceptance Criteria:
âœ“ 99.99% uptime requirement
âœ“ Zero data loss on crash
âœ“ Failover <30 seconds
âœ“ No system crashes in 48-hour soak test

PRIORITY 2: FUNCTIONAL CORRECTNESS (CRITICAL)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Why: Incorrect calculations = financial losses, regulatory issues.

Sub-characteristics:
a) Functional Completeness: All trading features work
b) Functional Correctness: Calculations accurate to 8 decimal places
c) Functional Appropriateness: Features suitable for trading

Test Strategy:
- Precision testing (decimal accuracy)
- Boundary testing (min/max trade values)
- Transaction testing (buy, sell, cancel orders)
- Reconciliation testing (match exchange records)
- Currency conversion accuracy

Example Critical Tests:
- Buy 1000 shares @ $123.456789 = $123,456.79 (rounded)
- Verify: No rounding errors accumulate
- Cross-check: Every trade matches exchange confirmation

Acceptance Criteria:
âœ“ 100% accuracy in financial calculations
âœ“ Zero discrepancies in reconciliation
âœ“ All trades execute within 100ms

PRIORITY 3: SECURITY (CRITICAL)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Why: Unauthorized access could lead to fraud, data breaches, regulatory
fines.

Sub-characteristics:
a) Confidentiality: Only authorized users access data
b) Integrity: Data not tampered with
c) Non-repudiation: All actions logged and traceable
d) Accountability: Audit trails
e) Authenticity: User identity verified

Test Strategy:
- Penetration testing (quarterly)
- Authentication testing (MFA required)
- Authorization testing (role-based access)
- Encryption testing (data at rest and in transit)
- Audit log testing (all trades logged)
- Compliance testing (SEC, FINRA regulations)

Example Security Tests:
- SQL injection attempts blocked
- Session hijacking prevented
- Brute force attacks detected
- Audit trail: Every trade logged with timestamp, user, IP

Acceptance Criteria:
âœ“ Pass penetration test (zero critical vulnerabilities)
âœ“ MFA enforced for all users
âœ“ 100% of transactions in audit log
âœ“ Data encrypted (AES-256)
âœ“ Compliance: SOX, PCI DSS

Other Important (But Secondary) Characteristics:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Priority 4: Performance Efficiency
- Trade execution <100ms
- Market data updates <50ms latency
- Load testing (10,000 concurrent users)

Priority 5: Usability
- Traders can execute trades in <3 seconds
- Clear error messages
- Intuitive interface

Justification:
In financial trading, incorrect data, downtime, or security breach can
result in:
- Direct financial losses (millions)
- Regulatory fines (SEC violations)
- Reputation damage (loss of clients)
- Legal liability

Therefore: Reliability, Correctness, and Security are non-negotiable.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Q25. You're setting up a CI/CD pipeline for a microservices architecture
with 20 services. How do you design the testing strategy to ensure fast
feedback while maintaining quality?

Answer:
Comprehensive microservices testing strategy:

ARCHITECTURE OVERVIEW:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

20 Microservices:
- Frontend: Web UI, Mobile API Gateway
- Backend: User Service, Order Service, Payment Service, Inventory Service,
  Notification Service, ... (20 total)
- Each service: Independent deployment, own database

Challenge: Testing 20 services interdependencies while maintaining fast
feedback.

TESTING STRATEGY BY LAYER:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Layer 1: Unit Tests (Per Service)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scope: Business logic within each service
Speed: <2 minutes per service
Frequency: Every commit (per service)

Example (Order Service):
- Test order creation logic
- Test order validation rules
- Test order state transitions
- Mock external dependencies

CI Pipeline Stage 1:
```yaml
order-service-pipeline:
  - name: Unit Tests
    run: npm test
    timeout: 2 min
    coverage: >80% required
```

Layer 2: Integration Tests (Per Service)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scope: Service with its dependencies (database, cache)
Speed: <5 minutes per service
Frequency: Every commit

Example (Order Service):
- Test: Service + PostgreSQL database
- Test: Service + Redis cache
- Use Docker Compose (spin up dependencies)
- Use Testcontainers (lightweight)

CI Pipeline Stage 2:
```yaml
- name: Integration Tests
  run: npm run test:integration
  services:
    - postgres:13
    - redis:6
  timeout: 5 min
```

Layer 3: Contract Tests (Service-to-Service)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scope: API contracts between services
Speed: <10 minutes (all contracts)
Frequency: Every commit
Tool: Pact (Contract Testing)

Example:
Order Service (Consumer) â†â†’ Payment Service (Provider)

Consumer Contract Test (Order Service):
```
Test: Order Service expects Payment Service to accept:
{
  "orderId": "123",
  "amount": 99.99,
  "currency": "USD"
}

And return:
{
  "transactionId": "abc",
  "status": "success"
}
```

Provider Contract Test (Payment Service):
Payment Service verifies it can fulfill this contract.

Benefits:
âœ“ Catch breaking changes before deployment
âœ“ Services can be deployed independently
âœ“ No need to run all 20 services for testing

Layer 4: Component Tests (Service in Isolation)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scope: Single service with mocked dependencies
Speed: <10 minutes per service
Frequency: Merge to main branch

Example (Order Service):
- Start Order Service
- Mock: Payment Service (stub API)
- Mock: Inventory Service (stub API)
- Test: Order Service end-to-end in isolation

Layer 5: End-to-End Tests (Critical Flows)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scope: Complete user journeys across services
Speed: 30 minutes (critical paths only)
Frequency: Nightly build, pre-production
Environment: Staging (all 20 services running)

Critical Flows (10-15 tests):
1. User Registration â†’ Login
2. Browse Products â†’ Add to Cart â†’ Checkout â†’ Payment â†’ Order Confirmation
3. View Order History
4. Process Return/Refund

CI Pipeline Stage 5:
```yaml
- name: E2E Tests
  run: npm run test:e2e
  environment: staging
  timeout: 30 min
  when: nightly OR merge to main
```

PARALLEL EXECUTION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Per-Service Pipelines (20 Parallel):
Each service has its own CI pipeline running in parallel:
- Order Service: Unit + Integration + Contract (7 min)
- Payment Service: Unit + Integration + Contract (7 min)
- ... (18 more services)

Total time: 7 minutes (parallel) vs 140 minutes (sequential)

DEPLOYMENT STRATEGY:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Independent Deployment:
- Each service deploys independently
- Contract tests prevent breaking changes
- Versioned APIs (backward compatible)

Progressive Deployment:
1. Deploy to Dev (auto)
2. Deploy to Staging (auto, run E2E tests)
3. Deploy to Production (canary: 5% â†’ 50% â†’ 100%)

MONITORING IN PRODUCTION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Synthetic Monitoring:
- Run critical flows every 5 minutes
- Alert if failures detected
- Example: Synthetic user completes checkout

Service Health Checks:
- Each service exposes /health endpoint
- Monitor: Response time, error rate, throughput

Distributed Tracing:
- Track requests across services
- Tool: Jaeger, Zipkin
- Identify bottlenecks and failures

TESTING TIME COMPARISON:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Traditional (All services together):
- Setup environment: 30 min
- Run all tests: 3 hours
- Total: 3.5 hours per commit âŒ Too slow

Microservices (Layered, Parallel):
- Commit Stage: 7 min (unit + integration + contract per service)
- Nightly: 30 min (E2E tests)
- Total: 7 min feedback âœ… Fast enough

KEY PRINCIPLES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Test pyramid still applies (60% unit, 30% integration, 10% E2E)
âœ“ Contract tests crucial for microservices
âœ“ Parallel execution essential
âœ“ Independent deployability
âœ“ Fail fast (unit tests catch most issues)
âœ“ E2E tests only for critical flows
âœ“ Monitoring in production (testing doesn't stop at deployment)

Result: Fast feedback (7 min), high quality, independent deployments

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
END OF ASSESSMENT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Summary & Key Takeaways

### Day 20 Key Concepts:

**1. Quality Standards Importance:**
   - Consistency: Common language, repeatable processes
   - Quality Assurance: Proven practices, risk mitigation
   - Compliance: Regulatory requirements, audit readiness
   - Efficiency: Avoid reinventing wheel, faster onboarding
   - Credibility: Professional recognition, market differentiation

**2. ISO/IEC 29119 - Software Testing Standard:**
   - 5 Parts: Concepts, Processes, Documentation, Techniques, Keyword-Driven
   - 3 Process Levels: Organizational, Management, Dynamic
   - Test Documentation Templates (Test Plan, Test Cases, Incident Reports)
   - Standardized Test Techniques (Black-box, White-box, Experience-based)
   - Implementation: 6-12 months, ROI positive after 12-18 months

**3. ISO/IEC 25010 - Software Quality Model:**
   - 8 Product Quality Characteristics:
     * Functional Suitability, Performance Efficiency, Compatibility
     * Usability, Reliability, Security, Maintainability, Portability
   - Each characteristic has sub-characteristics and test approaches
   - Quality metrics defined: measurement method, target value, acceptance criteria

**4. ISTQB Certification:**
   - Foundation Level: 40 questions, 60 min, 65% pass, no prerequisites
   - 6 Chapters: Fundamentals, SDLC, Static Testing, Techniques, Management, Tools
   - **Seven Testing Principles** (key concept):
     1. Testing shows presence of defects, not absence
     2. Exhaustive testing is impossible
     3. Early testing saves time and money
     4. Defects cluster together
     5. Pesticide paradox (need to change tests)
     6. Testing is context-dependent
     7. Absence-of-errors fallacy
   - Advanced Level: Test Manager, Test Analyst, Technical Test Analyst
   - Specialist: Agile Tester, Automation Engineer, Performance Tester, etc.
   - Benefits: Industry recognition, career advancement, 10-20% salary increase

**5. TMMi (Test Maturity Model Integration):**
   - 5 Maturity Levels:
     * Level 1: Initial (Chaotic, ad-hoc)
     * Level 2: Managed (Test planning, organized)
     * Level 3: Defined (Test organization, training, integrated)
     * Level 4: Measured (Metrics-driven, quantitative)
     * Level 5: Optimizing (Continuous improvement, defect prevention)
   - 16 Process Areas across levels
   - Assessment process: Preparation â†’ On-site â†’ Reporting â†’ Follow-up
   - Benefits: 15-30% defect reduction, 20-40% cost reduction, 10-25% faster TTM
   - Timeline: Level 1 â†’ Level 3 typically 12-18 months

**6. Alternative Process Improvement Models:**
   - TPI NEXT: Business-driven, 16 key areas, flexible improvement
   - STEP: 12-step systematic process by William Perry
   - CTP: 12 critical testing processes by Rex Black
   - Selection criteria: Organization size, budget, goals, flexibility needs

**7. Agile Testing Best Practices:**
   - Whole team quality ownership (not just QA)
   - Early and continuous testing (not at end of sprint)
   - Shift left testing (test from Day 1)
   - Test automation pyramid (60% unit, 30% API, 10% UI)
   - Continuous feedback loops
   - Agile Testing Quadrants:
     * Q1: Unit tests (technology-facing, guide development)
     * Q2: Functional tests (business-facing, validate features)
     * Q3: Exploratory testing (business-facing, critique product)
     * Q4: Performance/security (technology-facing, non-functional)
   - Definition of Done (DoD): Code complete + Testing complete + Documentation + Deployment ready

**8. DevOps & CI/CD Testing:**
   - DevOps = Development + Operations + QA (collaboration)
   - Continuous Integration (CI): Build and test every commit
   - Continuous Deployment (CD): Automatically deploy after tests pass
   - Test stages in pipeline:
     * Commit Stage: Unit tests (<10 min)
     * Acceptance Stage: Integration tests (20-30 min)
     * UAT Stage: Full regression (1-2 hours)
     * Production: Smoke tests + monitoring
   - Deployment strategies: Blue-Green, Canary, Rolling
   - Testing in production: Smoke tests, synthetic monitoring, feature flags, A/B testing
   - Shift left on security (DevSecOps): Security in every pipeline stage
   - Key metrics: Deployment frequency, lead time, MTTR, change failure rate

**9. Industry-Specific Testing:**
   - **Healthcare**: FDA 21 CFR Part 11, HIPAA, IEC 62304
     * Focus: Patient safety, data privacy, audit trails
   - **Financial**: PCI DSS, SOX, GDPR
     * Focus: Transaction accuracy, security, compliance
   - **E-commerce**: PCI DSS, performance, usability
     * Focus: Conversion rate, page load speed, checkout flow
   - **Automotive**: ISO 26262, AUTOSAR, MISRA C
     * Focus: Safety (ASIL levels), real-time, reliability
   - **Telecommunications**: 3GPP, 5G protocols
     * Focus: 99.999% uptime, latency <50ms, protocol compliance
   - **Gaming**: Performance (60 FPS), cross-platform, multiplayer lag

### Best Practices Summary:

**Standards & Compliance:**
âœ“ Adopt standards appropriate for organization size and industry
âœ“ Start with ISTQB Foundation for individual certification
âœ“ Use ISO 29119 templates for test documentation
âœ“ Consider TMMi for organizational process improvement
âœ“ Ensure compliance with industry-specific regulations

**Agile Testing:**
âœ“ Whole team testing (quality is everyone's responsibility)
âœ“ Test automation pyramid (more unit tests, fewer UI tests)
âœ“ Definition of Done with testing criteria
âœ“ Sprint testing from Day 1 (not just at end)
âœ“ Balance all four testing quadrants

**CI/CD:**
âœ“ Fast feedback (<10 min for unit tests)
âœ“ Reliable tests (no flaky tests)
âœ“ Test parallelization for speed
âœ“ Staged pipeline (commit â†’ acceptance â†’ UAT â†’ production)
âœ“ Monitor in production (testing doesn't stop at deployment)

**Process Improvement:**
âœ“ Assess current maturity level
âœ“ Create realistic improvement roadmap
âœ“ Gain stakeholder buy-in and budget
âœ“ Pilot before organization-wide rollout
âœ“ Measure ROI and benefits

### Common Pitfalls to Avoid:

âœ— Implementing standards without customization (one-size-fits-all)
âœ— Over-documentation (process becomes bureaucratic)
âœ— Certification as goal vs process improvement
âœ— Ignoring industry-specific compliance requirements
âœ— Slow CI/CD pipelines (>1 hour = developers ignore)
âœ— 100% manual testing in Agile (not sustainable)
âœ— Testing only at UI level (slow, brittle)
âœ— No testing in production (prod differs from test)

### Career Development:

**Certifications to Pursue:**
1. ISTQB Foundation (entry level, globally recognized)
2. ISTQB Advanced (Test Analyst or Technical Test Analyst)
3. ISTQB Agile Tester (if working in Agile teams)
4. Cloud certifications (AWS/Azure for DevOps testing)
5. Security certifications (Security+ for security testing)

**Skills to Develop:**
- Understanding of quality standards (ISO 29119, 25010)
- Process improvement (TMMi, TPI NEXT)
- Agile testing practices
- CI/CD pipeline testing
- Industry-specific knowledge (healthcare, finance, etc.)
- Communication (present standards adoption to stakeholders)

### Key Metrics:

**Process Maturity:**
- TMMi Level (1-5)
- Process areas achieved
- Audit compliance score
- Defect reduction %

**CI/CD:**
- Build success rate: >90%
- Build duration: <1 hour
- Deployment frequency: Multiple per day (high performers)
- Lead time: <1 day
- MTTR: <1 hour
- Change failure rate: <15%

**Quality:**
- Test coverage: >80%
- Defect detection rate: >90%
- Defect leakage: <5%
- Test automation: 60% unit, 30% integration, 10% UI

---

**Congratulations on completing Day 20\!**

**Study Time:** 6-7 hours

**Key Insight:** Industry standards and best practices provide a proven framework for quality testing. Whether following ISO standards, pursuing ISTQB certification, implementing TMMi maturity levels, or adopting Agile/DevOps practices, the goal is the same: deliver high-quality software efficiently through structured, repeatable, and continuously improving processes.

---

*End of Day 20 Study Guide*

